{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-14T16:44:59.416926700Z",
     "start_time": "2024-05-14T16:44:58.542133200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81d549c86aa44a9e9484001df6ae70fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "#access locaclly stored dataset in this path testing_for_error/asking_armor_data.json and is a json file\n",
    "\n",
    "train_dataset = load_dataset(\"json\", data_files=\"testing_for_error/Werewolf_data.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['Condition', 'Dialogue', 'Speaker', 'Event'],\n    num_rows: 27\n})"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T16:45:00.922219600Z",
     "start_time": "2024-05-14T16:45:00.913610Z"
    }
   },
   "id": "8f92a617057aac80",
   "execution_count": 145
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T16:45:04.671606300Z",
     "start_time": "2024-05-14T16:45:04.663999300Z"
    }
   },
   "id": "dad8e9abba327408",
   "execution_count": 146
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    \n",
    "    if example['Speaker'] == \"Any\":\n",
    "        npc_type = \"the NPC, that is of any type,\"\n",
    "        \n",
    "    elif \"Guard\" in example['Speaker']:\n",
    "        npc_type = f'the {example[\"Speaker\"]},'\n",
    "        \n",
    "    elif \"trainer\" in example['Event']:\n",
    "        npc_type = f'the trainer NPC, that is named {example['Speaker']},'\n",
    "        \n",
    "    elif example['Speaker'] == \"Housecarl\":\n",
    "        npc_type = \"the Housecarl,\"\n",
    "\n",
    "    else:\n",
    "        npc_type = f'the NPC, that is the type {example[\"Speaker\"]},'\n",
    "    \n",
    "    \n",
    "    if example['Event'] == \"Greeting\":\n",
    "        \n",
    "        return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, in the case of a {example['Event']}, between an NPC and the Player character, {npc_type} greets the player with the following dialogue: {example['Dialogue']}, in a {example['Tone']} tone.\"\"\"\n",
    "    \n",
    "    \n",
    "    if example['Event'] == \"Goodbye\":\n",
    "        \n",
    "        return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, in the case of a {example['Event']}, between an NPC and the Player character,{npc_type} tells their goodbyes to the Player with the following dialogue: {example['Dialogue']}.\"\"\"\n",
    "    \n",
    "    \n",
    "    if example['Event'] == \"NPCs fighting over a player's dropped item\":\n",
    "        \n",
    "        return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, in the event of {example['Event']}, there can be up to 5 different NPCs arguing over an item that the Player character dropped and up to 2 bystander NPCs commenting on the situation. Up to five lines of dialogue can be exchanged between up to five different NPCs that are arguing and up to two lines of bystander dialogue can be used by up to two different bystander NPCs, meaning that the conversation ends after a maximum of 7 lines of dialogue have been said. In this case one of the NPCs that takes part in the arguing and is {npc_type} says the following line: {example['Dialogue']}, as the {example['Speaker_Number']} line of the dialogue. \"\"\"\n",
    "    \n",
    "    if example['Event'] == \"NPC asking for the Player's dropped armor\":\n",
    "        \n",
    "        if example['Speaker'] == \"Player\":\n",
    "        \n",
    "            return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, in the event of an {example['Event']}, there is a conversation between the Player character and an NPC about the player's dropped item. \n",
    "In this case the Player character says the following line: {example['Dialogue']}, in response to the NPC's previous line of dialogue: {example['Response_to']}.\"\"\"\n",
    "        \n",
    "        if example['Response_to'] == \"nan\":\n",
    "            \n",
    "            return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, in the event of {example['Event']} there is a conversation between the Player character and an NPC about the player's dropped item. \n",
    "In this case {npc_type} says the following line: {example['Dialogue']}, in response to the Player character's previous line of dialogue: {example['Response_to']}.\"\"\"\n",
    "        else:\n",
    "            \n",
    "            return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, in the event of {example['Event']} there is a conversation between the Player character and an NPC about the player's dropped item. \n",
    "In this case {npc_type} says the following line: {example['Dialogue']}, to initiate a conversation about the Player's dropped item.\"\"\"\n",
    "    \n",
    "    if 'Condition' in example and example['Condition'] == \"in combat\":\n",
    "        \n",
    "        return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, when the Player character and a friendly NPC are {example['Condition']}, {npc_type} uses this line of dialogue: {example['Dialogue']}, when it is {example['Event']}.\"\"\"\n",
    "        \n",
    "    if 'Result' in example:\n",
    "        \n",
    "            return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, when the Player character tries to check if an NPC of any type can be persuaded, the NPC uses the following line of dialogue: {example['Dialogue']}, when {example['Event']} and as a result {example['Result']}.\"\"\"\n",
    "    \n",
    "    if example['Event'] == \"an NPC spots the Player character having an amulet of mara\":\n",
    "        \n",
    "        if example['Speaker'] == \"Player\":\n",
    "            \n",
    "            return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, when {example['Event']} an interaction begins between the two about the possibility of marriage. \n",
    "In this case the Player character says the following line: {example['Dialogue']}, as a response to the the NPC's dialogue line:{example['Response_to']}.\"\"\"\n",
    "        \n",
    "        if example['Response_to'] == \"nan\":\n",
    "            \n",
    "            return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, when {example['Event']} an interaction begins between the two about the possibility of marriage.\n",
    "In this case {npc_type} says the following line: {example['Dialogue']}, to initiate the conversation about marriage.\"\"\"\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, when {example['Event']} an interaction begins between the two about the possibility of marriage. \n",
    "In this case {npc_type} says the following line: {example['Dialogue']}, as a response to the the Player's dialogue line: {example['Response_to']}.\"\"\"\n",
    "    \n",
    "    if 'Race' in example:\n",
    "        \n",
    "        if example['Condition'] != \"nan\":\n",
    "            \n",
    "            return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the race of the Player character, so in the case of {example['Event']} if the Player's race is {example['Race']} the Guard reacts with this line of dialogue: {example['Dialogue']}, on the condition that the {example['Condition']}. \"\"\"\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the race of the Player character, so in the case of {example['Event']} if the Player's race is {example['Race']} the Guard reacts with this line of dialogue: {example['Dialogue']}. \"\"\"\n",
    "     \n",
    "    if 'Equipment' in example:\n",
    "        \n",
    "        if example['Condition'] != \"nan\":\n",
    "            \n",
    "            return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the equipment the player is holding or has equipped, so when in the case of a {example['Event']}, the Guard uses this line of dialogue: {example['Dialogue']}, to react to the Player's {example['Equipment']}, on the condition that {example['Condition']}.\"\"\"\n",
    "        \n",
    "        else: \n",
    "            \n",
    "            return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the equipment the player is holding or has equipped, so when in the case of a {example['Event']}, the Guard uses this line of dialogue: {example['Dialogue']}, to react to the Player's {example['Equipment']}.\"\"\"\n",
    "            \n",
    "    if 'Location' in example:\n",
    "        \n",
    "        if example['Condition'] != \"nan\":\n",
    "            \n",
    "            return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, Town Guards have special interactions with the Player character that are location based, meaning that the Guards sometimes interact with the Player using town specific dialogue.\n",
    "In this case a Guard in the town of {example['Location']} might use this line of dialogue: {example['Dialogue']}, when the Player interacts with them, on the condition that {example['Condition']}.\"\"\"\n",
    "        \n",
    "        else: \n",
    "            \n",
    "            return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, Town Guards have special interactions with the Player character that are location based, meaning that the Guards sometimes interact with the Player using town specific dialogue.\n",
    "In this case a Guard in the town of {example['Location']} might use this line of dialogue {example['Dialogue']}, when the Player interacts with them.\"\"\"\n",
    "        \n",
    "    if 'Condition' in example:\n",
    "        \n",
    "        if example['Condition'] != \"nan\":\n",
    "            \n",
    "            return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, in the event of {example['Event']}, {npc_type} says the following line to the Player ch+aracter: {example['Dialogue']}, on the condition that {example['Condition']}.\"\"\"\n",
    "    \n",
    "    return f\"\"\"In the world of Skyrim from the game Elder Scrolls V, in the event of {example['Event']}, {npc_type} says the following line to the Player character: {example['Dialogue']}.\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T16:45:04.879711700Z",
     "start_time": "2024-05-14T16:45:04.867139Z"
    }
   },
   "id": "131418b6535338bf",
   "execution_count": 147
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c575f9eea4514e0293aa417a374a747c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T13:21:09.212685800Z",
     "start_time": "2024-05-14T13:20:30.763040400Z"
    }
   },
   "id": "5e3d64226cbbc1df",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(prompt):\n",
    "    print(formatting_func(prompt))\n",
    "    return tokenizer(formatting_func(prompt))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T16:45:07.330068400Z",
     "start_time": "2024-05-14T16:45:07.321066500Z"
    }
   },
   "id": "cfe4ef3ec3c37141",
   "execution_count": 148
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/27 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e344e502ac334cb08b21f307dd505026"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the Guard, says the following line to the Player ch+aracter: \"Werewolf!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the Guard, says the following line to the Player ch+aracter: \"It's a werewolf! To arms! To arms!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the Guard, says the following line to the Player ch+aracter: \"By the gods! It..it can't be!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type MaleCommoner, says the following line to the Player ch+aracter: \"Come on! You monster!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type MaleCommonerAccented, says the following line to the Player ch+aracter: \"Come on! You monster!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type FemaleCommoner, says the following line to the Player ch+aracter: \"Come on! You monster!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type MaleEvenToned, says the following line to the Player ch+aracter: \"Come on! You monster!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type MaleEvenTonedAccented, says the following line to the Player ch+aracter: \"Come on! You monster!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type FemaleEvenToned, says the following line to the Player ch+aracter: \"Come on! You monster!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type MaleNord, says the following line to the Player ch+aracter: \"Come on! You monster!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type FemaleNord, says the following line to the Player ch+aracter: \"Come on! You monster!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type MaleCommoner, says the following line to the Player ch+aracter: \"Die, you filthy beast!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type MaleCommonerAccented, says the following line to the Player ch+aracter: \"Die, you filthy beast!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type FemaleCommoner, says the following line to the Player ch+aracter: \"Die, you filthy beast!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type MaleEvenToned, says the following line to the Player ch+aracter: \"Die, you filthy beast!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type MaleEvenTonedAccented, says the following line to the Player ch+aracter: \"Die, you filthy beast!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type FemaleEvenToned, says the following line to the Player ch+aracter: \"Die, you filthy beast!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type MaleNord, says the following line to the Player ch+aracter: \"Die, you filthy beast!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type FemaleNord, says the following line to the Player ch+aracter: \"Die, you filthy beast!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type MaleCommoner, says the following line to the Player ch+aracter: \"Werewolf! Kill the monster!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type MaleCommonerAccented, says the following line to the Player ch+aracter: \"Werewolf! Kill the monster!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type FemaleCommoner, says the following line to the Player ch+aracter: \"Werewolf! Kill the monster!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type MaleEvenToned, says the following line to the Player ch+aracter: \"Werewolf! Kill the monster!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type MaleEvenTonedAccented, says the following line to the Player ch+aracter: \"Werewolf! Kill the monster!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type FemaleEvenToned, says the following line to the Player ch+aracter: \"Werewolf! Kill the monster!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type MaleNord, says the following line to the Player ch+aracter: \"Werewolf! Kill the monster!\", on the condition that the Player having transformed into a werewolf.\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of Player is a werewolf, the NPC, that is the type FemaleNord, says the following line to the Player ch+aracter: \"Werewolf! Kill the monster!\", on the condition that the Player having transformed into a werewolf.\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T16:45:08.206249700Z",
     "start_time": "2024-05-14T16:45:08.140797900Z"
    }
   },
   "id": "d6438a2ecf446de0",
   "execution_count": 149
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Event': \"NPCs fighting over a player's dropped item\", 'Speaker': 'FemaleNord', 'Speaker_Number': '1st ', 'Dialogue': '\"Who left that here?\"', 'input_ids': [1, 560, 272, 1526, 302, 3891, 4369, 321, 477, 272, 2039, 22810, 263, 2522, 1584, 28713, 550, 28725, 297, 272, 1951, 302, 418, 4199, 28713, 8552, 754, 264, 4385, 28742, 28713, 7679, 2515, 28725, 736, 541, 347, 582, 298, 28705, 28782, 1581, 418, 4199, 28713, 21440, 754, 396, 2515, 369, 272, 13684, 3233, 7679, 304, 582, 298, 28705, 28750, 486, 1793, 263, 418, 4199, 28713, 4517, 288, 356, 272, 4620, 28723, 4324, 298, 3359, 4715, 302, 19198, 541, 347, 439, 11247, 1444, 582, 298, 3359, 1581, 418, 4199, 28713, 369, 460, 21440, 304, 582, 298, 989, 4715, 302, 486, 1793, 263, 19198, 541, 347, 1307, 486, 582, 298, 989, 1581, 486, 1793, 263, 418, 4199, 28713, 28725, 5746, 369, 272, 7114, 9675, 1024, 264, 7228, 302, 28705, 28787, 4715, 302, 19198, 506, 750, 773, 28723, 560, 456, 1222, 624, 302, 272, 418, 4199, 28713, 369, 4347, 744, 297, 272, 21440, 304, 349, 272, 418, 4199, 28725, 369, 349, 1212, 18375, 883, 28759, 556, 28725, 2627, 272, 2296, 1407, 28747, 345, 11447, 1749, 369, 1236, 28804, 548, 293, 272, 28705, 28740, 303, 28705, 1407, 302, 272, 19198, 28723, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T13:07:07.570765200Z",
     "start_time": "2024-05-14T13:07:07.559414Z"
    }
   },
   "id": "82b3ef4eba92a209",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset['train']]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset['train']]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe34416de1121bf2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "max_length = 120  # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b3e76e5d59b83b4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4121ff13e365288",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(tokenized_train_dataset['train'][1]['input_ids'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "272efb57d867178d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5673a5175e6f2638",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "eval_prompt = (\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "678f82c73601a318",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Init an eval tokenizer that doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0],\n",
    "                                skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47c8339c7d3e3ea2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from peft import PeftConfig\n",
    "\n",
    "adapter_model_id = \"ybelkada/opt-350m-lora\"\n",
    "peft_config = PeftConfig.from_pretrained(adapter_model_id)\n",
    "# to initiate with random weights\n",
    "peft_config.init_lora_weights = False\n",
    "\n",
    "model.add_adapter(peft_config)\n",
    "model.enable_adapters()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2441ddcd1a5181df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"###Character: \" + test_dataset['train'][200]['character'] + \"\\n  responded with: \" + test_dataset['train'][200][\n",
    "    'dialogue'] + \"\\n to what was said by: \" + test_dataset['train'][200]['response_to'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ab714e941181fd6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "570b93f08b1b61eb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddf562f6b54c4893",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fe694a164bb1ea8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6354fba6c3915b3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:  # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fcbe8317af8659a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = accelerator.prepare_model(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec3566a59128b91",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"own-finetune\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_val_dataset[\"train\"],\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=200,\n",
    "        learning_rate=2.5e-5,  # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,  # When to start reporting loss\n",
    "        logging_dir=\"./logs\",  # Directory for storing logs\n",
    "        save_strategy=\"steps\",  # Save the model checkpoint every logging step\n",
    "        save_steps=25,  # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\",  # Evaluate the model every logging step\n",
    "        eval_steps=25,  # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,\n",
    "        # Perform evaluation at the end of training         # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"  # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c48d66dfa4929c8f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea90e93a904c5d4a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"mistral-own-finetune/checkpoint-50\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e154dc87f95c4f41",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "eval_prompt = \"Start a conversation where Dutch van der Linde plans a new heist\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=280, repetition_penalty=1.15)[0],\n",
    "                                skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16f5ddad06c7fa1b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Rouge Score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bef0d5c5cee19e4f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "generated_dialogues = [\"Doctor:  I'm afraid you have tuberculosis. We need to start treatment right away.\",\n",
    "                       \"Arthur Morgan: Tuberculosis... That's a death sentence isn't it?\"]\n",
    "\n",
    "reference_dialogues = [\"Doctor: You got tuberculosis. I’m really sorry for you, son, it’s a hell of a thing.\",\n",
    "                       \"Arthur Morgan: Aah… What is it?\"]\n",
    "\n",
    "print(len(reference_dialogues))\n",
    "\n",
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "rouge_scores = rouge.get_scores(' '.join(generated_dialogues), ' '.join(reference_dialogues[0]))\n",
    "\n",
    "# Output the scores \n",
    "\n",
    "print(f\"ROUGE: {rouge_scores}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9c66b4e9da55ee4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "\n",
    "# Tokenize the reference and generated dialogues into words\n",
    "reference_dialogues = [\n",
    "    [\"Doctor:\", \"You\", \"got\", \"tuberculosis.\", \"I’m\", \"really\", \"sorry\", \"for\", \"you,\", \"son,\", \"it’s\", \"a\", \"hell\", \"of\", \"a\", \"thing.\"],\n",
    "    [\"Arthur\", \"Morgan:\", \"Aah…\", \"What\", \"is\", \"it?\"]\n",
    "]\n",
    "generated_dialogues = [\n",
    "    [\"Doctor:\", \"I'm\", \"afraid\", \"you\", \"have\", \"tuberculosis.\", \"We\", \"need\", \"to\", \"start\", \"treatment\", \"right\", \"away.\"],\n",
    "    [\"Arthur\", \"Morgan:\", \"Tuberculosis...\", \"That's\", \"a\", \"death\", \"sentence\", \"isn't\", \"it?\"]\n",
    "]\n",
    "\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = sentence_bleu(reference_dialogues, generated_dialogues)\n",
    "print(f\"BLEU: {bleu_score}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b738655740170ad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "728c8d2a5290e8c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
