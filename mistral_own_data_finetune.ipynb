{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-23T17:54:18.026758200Z",
     "start_time": "2024-05-23T17:54:17.177529700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a83f4c138ca94a168fbeae5762a97f99"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "#access locaclly stored dataset in this path testing_for_error/asking_armor_data.json and is a json file\n",
    "\n",
    "train_dataset = load_dataset(\"json\", data_files=\"testing_for_error/wedding_data.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['Event', 'Condition', 'Speaker', 'Dialogue'],\n    num_rows: 135\n})"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T17:54:18.693089400Z",
     "start_time": "2024-05-23T17:54:18.684300800Z"
    }
   },
   "id": "8f92a617057aac80",
   "execution_count": 251
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T17:54:19.676626300Z",
     "start_time": "2024-05-23T17:54:19.668582500Z"
    }
   },
   "id": "dad8e9abba327408",
   "execution_count": 252
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    \n",
    "    if 'Monologue' in example:\n",
    "        \n",
    "        return f\"\"\"\n",
    "In the following text, there is a description of the introductory monologue in video games. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the title of the current game will always be enclosed inside \" \", the monologue will always be enclosed inside $ $, and the context will be enclosed inside # #.\n",
    "         \n",
    "<START>\n",
    "In video games, sometimes there is an introductory monologue delivered by a Speaker. The Speaker can either be an unknown narrator or a character in the game, and they introduce the Player to the world, the story, and the setting of the game. For the game \"{example['Game']}\", the introductory monologue is as follows:\n",
    "\n",
    "${example['Monologue']}$\n",
    "\n",
    "This monologue is based on the game's setting, world, story, and the Player's role in the game. Here is some context describing these elements:\n",
    "\n",
    "#{example['Context']}#\n",
    "<END>\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    description = f\"\"\"The following text describes a line of dialogue used by an NPC in a certain event. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed inside & &, the speaker will be enclosed inside % %, the line spoken will be enclosed inside \" \".\n",
    "\n",
    "\"\"\"\n",
    "    if example['Event'] == \"Greeting\":\n",
    "        \n",
    "        description = f\"\"\"The following text describes a greeting exchange between the Player and an NPC based on an event. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed inside & &, the type of speaker will be enclosed inside % %, the line spoken will be enclosed inside \" \", and the tone of the line will be enclosed inside ; ;.\n",
    "\n",
    "\"\"\"\n",
    "    elif example['Event'] == \"NPCs fighting over a Player's dropped item\":\n",
    "        \n",
    "        description = f\"\"\"The following text describes an exchange where multiple NPCs are fighting over a Player's dropped item and one of them uses a line of dialogue. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed inside & &, the number of the current spoken line in the dialogue will be enclosed inside ~ ~, the line spoken will be enclosed inside \" \", and the speaker will be enclosed inside % %.\n",
    "\n",
    "\"\"\"\n",
    "    elif 'Condition' in example and example['Condition'] == \"in combat\":\n",
    "        \n",
    "        description = f\"\"\"The following text states which line of dialogue a friendly NPC uses when it is in combat. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed inside & &, the condition will be enclosed inside ( ), the line spoken will be enclosed inside \" \", and the speaker will be enclosed inside % %.\n",
    "\n",
    "\"\"\"\n",
    "    elif 'Result' in example:\n",
    "        \n",
    "        description = f\"\"\"The following text states which line of dialogue is used by an NPC when the Player character tries to persuade them. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed inside & &, the line spoken will be enclosed inside \" \", the result of the event will be enclosed inside @ @ and the speaker enclosed inside % %.\n",
    "\n",
    "\"\"\"\n",
    "    elif 'Race' in example:\n",
    "        \n",
    "        description = f\"\"\"The following text describes the reaction of a Guard based on the Player's race. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed inside & &, the speaker will be enclosed inside % %, the line spoken will be enclosed inside \" \", the race of the Player will be enclosed inside * *, and the condition , if there is one, will be enclosed inside ( ).\n",
    "\n",
    "\"\"\"\n",
    "    elif 'Equipment' in example:\n",
    "        \n",
    "        description = f\"\"\"The following text describes the reaction of a Guard based on the Player's equipment. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed inside & &, the speaker will be enclosed inside % %, the line spoken will be enclosed inside \" \", the equipment of the Player will be enclosed inside [ ], and the condition , if there is one, will be enclosed inside ( ).\n",
    "\n",
    "\"\"\"\n",
    "    elif 'Location' in example:\n",
    "        \n",
    "        description = f\"\"\"The following text describes a special interaction of a Guard based on the Player's location. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed inside & &, the speaker will be enclosed inside % %, the line spoken will be enclosed inside \" \", the location of the Player will be enclosed inside ^ ^, and the condition , if there is one, will be enclosed inside ( ).\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "    elif 'Response_to' in example:\n",
    "        \n",
    "        description = f\"\"\"The following text describes a part of a dialogue between and NPC and the Player in the case of a certain event. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed inside & &, the speaker will be enclosed inside % %, the line spoken will be enclosed inside \" \", and the line that the speaker responds to, will be enclosed inside | |.\n",
    "\n",
    "\"\"\"\n",
    "    elif 'Condition' in example and example['Condition'] != \"nan\":\n",
    "        \n",
    "        description = f\"\"\"The following text describes a line of dialogue used by an NPC in a certain event under a condition. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed inside & &, the speaker will be enclosed inside % %, the line spoken will be enclosed inside \" \", and the condition, will be enclosed inside ( ).\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    \n",
    "    if example['Speaker'] == \"Any\":\n",
    "        \n",
    "        npc_type = \"the NPC, that is of any type\"\n",
    "        \n",
    "    elif \"Guard\" in example['Speaker']:\n",
    "        \n",
    "        npc_type = f'the {example[\"Speaker\"]}'\n",
    "        \n",
    "    elif \"trainer\" in example['Event']:\n",
    "        \n",
    "        npc_type = f'the trainer NPC, that is named {example['Speaker']}'\n",
    "        \n",
    "    elif example['Speaker'] == \"Housecarl\":\n",
    "        \n",
    "        npc_type = \"the Housecarl\"\n",
    "\n",
    "    else:\n",
    "        \n",
    "        npc_type = f'the NPC, that is the type {example[\"Speaker\"]}'\n",
    "    \n",
    "    \n",
    "    \n",
    "    if example['Event'] == \"Greeting\":\n",
    "        \n",
    "        return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the case of a &{example['Event']}&, between an NPC and the Player character, %{npc_type}% greets the Player with the following dialogue: {example['Dialogue']}, in a ;{example['Tone']}; tone.\n",
    "<END>\"\"\"\n",
    "    \n",
    "    \n",
    "    if example['Event'] == \"Goodbye\":\n",
    "        \n",
    "        return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the case of a &{example['Event']}&, between an NPC and the Player character,%{npc_type}% tells their goodbyes to the Player with the following dialogue: {example['Dialogue']}.\n",
    "<END>\"\"\"\n",
    "    \n",
    "    \n",
    "    if example['Event'] == \"NPCs fighting over a Player's dropped item\":\n",
    "        \n",
    "        return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of &{example['Event']}&, there can be up to 5 different NPCs arguing over an item that the Player character dropped and up to 2 bystander NPCs commenting on the situation. Up to five lines of dialogue can be exchanged between up to five different NPCs that are arguing and up to two lines of bystander dialogue can be used by up to two different bystander NPCs, meaning that the conversation ends after a maximum of 7 lines of dialogue have been said. In this case one of the NPCs that takes part in the arguing and %{npc_type}%, says the following line: {example['Dialogue']}, as the ~{example['Line_of_dialogue']}~ line of the dialogue.\n",
    "<END>\"\"\"\n",
    "    \n",
    "    if example['Event'] == \"NPC asking for the Player's dropped armor\":\n",
    "\n",
    "        if example['Speaker'] == \"Player\":\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of an &{example['Event']}&, there is a conversation between the Player character and an NPC about the Player's dropped item. \n",
    "In this case the %Player% character says the following line: {example['Dialogue']}, in response to the NPC's previous line of dialogue: |{example['Response_to']}|.\n",
    "<END>\"\"\"\n",
    "        \n",
    "        if example['Response_to'] != \"nan\":\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of an &{example['Event']}& there is a conversation between the Player character and an NPC about the Player's dropped item. \n",
    "In this case %{npc_type}%, says the following line: {example['Dialogue']}, in response to the Player character's previous line of dialogue: |{example['Response_to']}|.\n",
    "<END>\"\"\"\n",
    "        else:\n",
    "\n",
    "            return description + f\"\"\"<<START>>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of an &{example['Event']}& there is a conversation between the Player character and an NPC about the Player's dropped item. \n",
    "In this case %{npc_type}%, says the following line: {example['Dialogue']}, to initiate a conversation about the Player's dropped item.\n",
    "<END>\"\"\"\n",
    "    \n",
    "    if 'Condition' in example and example['Condition'] == \"in combat\":\n",
    "        \n",
    "        return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when the Player character and a friendly NPC are ({example['Condition']}), %{npc_type}%, uses this line of dialogue: {example['Dialogue']}, when it is &{example['Event']}&.\n",
    "<END>\"\"\"\n",
    "        \n",
    "    if 'Result' in example:\n",
    "        \n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when the Player character tries to check if an NPC of any type can be persuaded, the %{npc_type}%, uses the following line of dialogue: {example['Dialogue']}, when &{example['Event']}& and as a result @{example['Result']}@.\n",
    "<END>\"\"\"\n",
    "    \n",
    "    if example['Event'] == \"an NPC spots the Player character having an amulet of mara\":\n",
    "        \n",
    "        if example['Speaker'] == \"Player\":\n",
    "            \n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when &{example['Event']}& an interaction begins between the two about the possibility of marriage. \n",
    "In this case the %Player% character, says the following line: {example['Dialogue']}, as a response to the the NPC's dialogue line: |{example['Response_to']}|.\n",
    "<END>\"\"\"\n",
    "        \n",
    "        if example['Response_to'] == \"nan\":\n",
    "            \n",
    "            return description +  f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when &{example['Event']}& an interaction begins between the two about the possibility of marriage.\n",
    "In this case %{npc_type}%, says the following line: {example['Dialogue']}, to initiate the conversation about marriage.\n",
    "<END>\"\"\"\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when &{example['Event']}& an interaction begins between the two about the possibility of marriage. \n",
    "In this case %{npc_type}%, says the following line: {example['Dialogue']}, as a response to the the Player's dialogue line: |{example['Response_to']}|.\n",
    "<END>\"\"\"\n",
    "    \n",
    "    if 'Race' in example:\n",
    "        \n",
    "        if example['Condition'] != \"nan\":\n",
    "            \n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the race of the Player character, so in the case of &{example['Event']}& if the Player's race is *{example['Race']}*, the %Guard% reacts with this line of dialogue: {example['Dialogue']}, on the condition that the ({example['Condition']}).\n",
    "<END>\"\"\"\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the race of the Player character, so in the case of &{example['Event']}& if the Player's race is *{example['Race']}*, the %Guard% reacts with this line of dialogue: {example['Dialogue']}.\n",
    "<END>\"\"\"\n",
    "     \n",
    "    if 'Equipment' in example:\n",
    "        \n",
    "        if example['Condition'] != \"nan\":\n",
    "            \n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the equipment the Player is holding or has equipped, so when in the case of a &{example['Event']}&, the %Guard% uses this line of dialogue: {example['Dialogue']}, to react to the Player's [{example['Equipment']}], on the condition that ({example['Condition']}).\n",
    "<END>\"\"\"\n",
    "        \n",
    "        else: \n",
    "            \n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the equipment the Player is holding or has equipped, so when in the case of a &{example['Event']}&, the %Guard% uses this line of dialogue: {example['Dialogue']}, to react to the Player's [{example['Equipment']}].\n",
    "<END>\"\"\"\n",
    "            \n",
    "    if 'Location' in example:\n",
    "        \n",
    "        if example['Condition'] != \"nan\":\n",
    "            \n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, &Town Guards have special interactions with the Player character that are location based&, meaning that the Guards sometimes interact with the Player using town specific dialogue.\n",
    "In this case a %Guard% in the town of ^{example['Location']}^ might use this line of dialogue: {example['Dialogue']}, when the Player interacts with them, on the condition that ({example['Condition']}).\n",
    "<END>\"\"\"\n",
    "        \n",
    "        else: \n",
    "            \n",
    "            return description + f\"\"\"<START>\n",
    "rtebgIn the world of Skyrim from the game Elder Scrolls V, &Town Guards have special interactions with the Player character that are location based&, meaning that the Guards sometimes interact with the Player using town specific dialogue.\n",
    "In this case a %Guard% in the town of ^{example['Location']}^ might use this line of dialogue {example['Dialogue']}, when the Player interacts with them.\n",
    "<END>\"\"\"\n",
    "        \n",
    "    if 'Condition' in example:\n",
    "        \n",
    "        if example['Condition'] != \"nan\":\n",
    "            \n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of &{example['Event']}&, %{npc_type}%, says the following line to the Player character: {example['Dialogue']}, on the condition that ({example['Condition']}).\n",
    "<END>\"\"\"\n",
    "    \n",
    "    return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of &{example['Event']}&, %{npc_type}%, says the following line to the Player character: {example['Dialogue']}.\n",
    "<END>\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T17:58:45.111792800Z",
     "start_time": "2024-05-23T17:58:45.105480700Z"
    }
   },
   "id": "131418b6535338bf",
   "execution_count": 257
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1697a590f9c40349c6863cb72bf04af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T17:13:37.996924600Z",
     "start_time": "2024-05-23T17:12:58.829622700Z"
    }
   },
   "id": "5e3d64226cbbc1df",
   "execution_count": 186
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(prompt):\n",
    "    #write the resulting prompt in a txt file\n",
    "    formatted_prompt = formatting_func(prompt)\n",
    "    with open(\"prompt.txt\", \"a\") as f:\n",
    "        f.write(formatted_prompt)\n",
    "    \n",
    "    return tokenizer(formatting_func(prompt))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T17:54:27.687275700Z",
     "start_time": "2024-05-23T17:54:27.678092400Z"
    }
   },
   "id": "cfe4ef3ec3c37141",
   "execution_count": 254
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following text describes a line of dialogue used by an NPC in a certain event. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be inside & &, the speaker will be inside % %, the line spoken will be inside \" \".\n",
      "\n",
      "<START>\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of &the wedding ceremony between the Player and the NPC&, %the NPC, that is the type FemaleElfHaughty%, says the following line to the Player character: It's a simple ceremony, but it'll do. You're here. That's enough.\".\n",
      "<END>\n"
     ]
    }
   ],
   "source": [
    "#format one example\n",
    "print(formatting_func(train_dataset[57]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T17:57:15.298296700Z",
     "start_time": "2024-05-23T17:57:15.283483800Z"
    }
   },
   "id": "6a540269d58fd473",
   "execution_count": 256
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/50 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40ae313b45b14dfbaae7919aca64fc75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T17:11:28.546799200Z",
     "start_time": "2024-05-23T17:11:26.576315300Z"
    }
   },
   "id": "d6438a2ecf446de0",
   "execution_count": 180
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Monologue': \"laudia, my dearest sister, I have been in Arra a week now, safe and in high spirits but prepared for the worst. The men and women who have fed and sheltered me here also give me warning that the road to Masaf is overrun by mercenaries and bandits not native to this land. What this could mean, I had dread to guess when I first set out from Roma 10 months ago. I did so with a single purpose: to discover what our father did not. In a letter written the year before my birth, he makes mention of a library hidden beneath the stones of Masia Castle, a sanctum full of invaluable wisdom.  So, what will I find when I arrive there? Who will greet me? I host an eager Templar, as I fear most strongly, or nothing but the whistling of a cold and lonely wind. Masaf has not been home to the Assassins for almost 300 years now. Can we still claim it for our own? Are we welcome there? Ah, I am wary of this fight, Claudia, not because I am tired, but because our struggle seems to move in one direction only: towards chaos. Today, I have more questions than answers.  This is why I've come so far: to find clarity, to find the wisdom left behind by the great Aler so that I may better understand the purpose of our fight and my place in it. Should anything happen to me, Claudia, should my skills fail me or my ambition lead me astray, do not seek retribution or revenge in my memory, but fight to continue the search for truth so that all may benefit. My story is one of many thousands, and the world will not suffer if it ends too soon.\", 'Game': \"Assassin's Creed: Revelations\", 'Context': 'In \"Assassin\\'s Creed: Revelations\", the introductory monologue is delivered by Ezio Auditore in a letter to his sister, Claudia, setting the stage for his journey. Ezio has arrived in Masyaf, seeking a hidden library mentioned by their father. This library, located beneath Masyaf Castle, is believed to contain invaluable wisdom and secrets left by the legendary Assassin, Altair. Players take on the role of Ezio, now a seasoned Master Assassin, as he navigates the perilous journey to uncover the hidden knowledge. The road to Masyaf is fraught with mercenaries and bandits, making the mission dangerous and uncertain. As Ezio, players must use their skills and cunning to overcome these threats, unravel the mysteries of the past, and gain insight into the true purpose of the Assassin Brotherhood. The game delves into Ezio\\'s introspective quest for clarity and understanding, while also connecting his fate with that of Altair and Desmond Miles, bridging the gaps between different eras of the Assassin\\'s Creed saga.', 'input_ids': [1, 28705, 13, 657, 272, 2296, 2245, 28725, 736, 349, 264, 5436, 302, 272, 24671, 2478, 695, 1326, 1165, 441, 297, 3798, 3897, 28723, 415, 2245, 622, 347, 481, 12848, 2373, 523, 12241, 28767, 304, 523, 5000, 13902, 1387, 460, 2948, 5879, 369, 5580, 865, 298, 272, 2245, 28747, 272, 3941, 302, 272, 1868, 2039, 622, 1743, 347, 3416, 345, 7717, 272, 1326, 1165, 441, 622, 1743, 347, 3416, 429, 28542, 304, 272, 2758, 622, 347, 3416, 422, 422, 28723, 13, 2600, 13, 28789, 12241, 28767, 13, 657, 3798, 3897, 28725, 4662, 736, 349, 396, 24671, 2478, 695, 1326, 1165, 441, 11448, 486, 264, 8819, 4776, 28723, 415, 8819, 4776, 541, 2477, 347, 396, 9038, 9819, 1028, 442, 264, 3233, 297, 272, 2039, 28725, 304, 590, 13097, 272, 13684, 298, 272, 1526, 28725, 272, 2838, 28725, 304, 272, 5587, 302, 272, 2039, 28723, 1263, 272, 2039, 345, 7226, 489, 262, 28742, 28713, 334, 2816, 28747, 399, 3443, 697, 548, 272, 24671, 2478, 695, 1326, 1165, 441, 349, 390, 6104, 28747, 13, 13, 28776, 2220, 554, 515, 28725, 586, 340, 11713, 5668, 28725, 315, 506, 750, 297, 1010, 520, 264, 1819, 1055, 28725, 5023, 304, 297, 1486, 20394, 562, 7998, 354, 272, 8748, 28723, 415, 1683, 304, 2525, 693, 506, 15441, 304, 8816, 8308, 528, 1236, 835, 2111, 528, 9536, 369, 272, 3878, 298, 9183, 2015, 349, 754, 3220, 486, 3051, 15698, 4838, 304, 4028, 1046, 459, 8271, 298, 456, 2533, 28723, 1824, 456, 829, 2072, 28725, 315, 553, 17790, 298, 5102, 739, 315, 907, 808, 575, 477, 17246, 28705, 28740, 28734, 3370, 3584, 28723, 315, 863, 579, 395, 264, 2692, 6032, 28747, 298, 5191, 767, 813, 3140, 863, 459, 28723, 560, 264, 5498, 4241, 272, 879, 1159, 586, 5950, 28725, 400, 2870, 4389, 302, 264, 7607, 7918, 10042, 272, 17388, 302, 9183, 515, 17085, 28725, 264, 24309, 383, 2173, 302, 297, 1052, 10500, 16679, 28723, 28705, 1537, 28725, 767, 622, 315, 1300, 739, 315, 12688, 736, 28804, 6526, 622, 3656, 299, 528, 28804, 315, 3434, 396, 15381, 320, 2713, 283, 28725, 390, 315, 4813, 1080, 12287, 28725, 442, 2511, 562, 272, 20978, 1905, 302, 264, 5256, 304, 23275, 5535, 28723, 9183, 2015, 659, 459, 750, 1611, 298, 272, 3348, 489, 1126, 354, 2779, 28705, 28770, 28734, 28734, 1267, 1055, 28723, 2418, 478, 1309, 3452, 378, 354, 813, 1216, 28804, 4867, 478, 10058, 736, 28804, 10103, 28725, 315, 837, 275, 628, 302, 456, 3992, 28725, 25630, 515, 28725, 459, 1096, 315, 837, 10272, 28725, 562, 1096, 813, 11371, 3969, 298, 2318, 297, 624, 5007, 865, 28747, 5083, 21007, 28723, 8784, 28725, 315, 506, 680, 4224, 821, 11194, 28723, 28705, 851, 349, 2079, 315, 28742, 333, 1567, 579, 2082, 28747, 298, 1300, 25312, 28725, 298, 1300, 272, 16679, 1749, 2910, 486, 272, 1598, 976, 263, 579, 369, 315, 993, 1873, 2380, 272, 6032, 302, 813, 3992, 304, 586, 1633, 297, 378, 28723, 10934, 2424, 4804, 298, 528, 28725, 25630, 515, 28725, 1023, 586, 6266, 3747, 528, 442, 586, 4358, 685, 1736, 528, 9597, 919, 28725, 511, 459, 5695, 1699, 1030, 296, 442, 25824, 297, 586, 4733, 28725, 562, 3992, 298, 3688, 272, 3472, 354, 5307, 579, 369, 544, 993, 7949, 28723, 1984, 2838, 349, 624, 302, 1287, 8577, 28725, 304, 272, 1526, 622, 459, 13572, 513, 378, 9675, 1368, 3403, 5910, 13, 13, 3260, 1326, 1165, 441, 349, 2818, 356, 272, 2039, 28742, 28713, 5587, 28725, 1526, 28725, 2838, 28725, 304, 272, 13684, 28742, 28713, 3905, 297, 272, 2039, 28723, 4003, 349, 741, 2758, 18063, 1167, 5176, 28747, 13, 13, 28771, 657, 345, 7226, 489, 262, 28742, 28713, 334, 2816, 28747, 399, 3443, 697, 548, 272, 24671, 2478, 695, 1326, 1165, 441, 349, 11448, 486, 23963, 691, 14421, 279, 431, 297, 264, 5498, 298, 516, 5668, 28725, 25630, 515, 28725, 5587, 272, 5430, 354, 516, 8123, 28723, 23963, 691, 659, 6792, 297, 351, 5826, 2015, 28725, 11246, 264, 7918, 7607, 7083, 486, 652, 3140, 28723, 851, 7607, 28725, 5651, 10042, 351, 5826, 2015, 17085, 28725, 349, 7761, 298, 7001, 297, 1052, 10500, 16679, 304, 19376, 1749, 486, 272, 26361, 3348, 489, 262, 28725, 16589, 992, 28723, 26500, 1388, 356, 272, 3905, 302, 23963, 691, 28725, 1055, 264, 3302, 286, 9361, 3348, 489, 262, 28725, 390, 400, 27555, 1002, 272, 660, 309, 607, 8123, 298, 521, 3649, 272, 7918, 4788, 28723, 415, 3878, 298, 351, 5826, 2015, 349, 6388, 786, 407, 395, 3051, 15698, 4838, 304, 4028, 1046, 28725, 2492, 272, 7023, 9259, 304, 12518, 28723, 1136, 23963, 691, 28725, 5117, 1580, 938, 652, 6266, 304, 277, 13860, 298, 17132, 1167, 19843, 28725, 521, 28712, 3177, 272, 16092, 497, 302, 272, 2609, 28725, 304, 8356, 16164, 778, 272, 1132, 6032, 302, 272, 3348, 489, 262, 22513, 5079, 28723, 415, 2039, 882, 1855, 778, 23963, 691, 28742, 28713, 716, 2737, 8524, 1825, 354, 25312, 304, 6399, 28725, 1312, 835, 19135, 516, 16942, 395, 369, 302, 16589, 992, 304, 2535, 8025, 25264, 28725, 1170, 313, 3080, 272, 27612, 1444, 1581, 1234, 293, 302, 272, 3348, 489, 262, 28742, 28713, 334, 2816, 268, 8882, 28723, 28771, 13, 28789, 5000, 28767, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[12])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T17:13:40.610946500Z",
     "start_time": "2024-05-23T17:13:40.590091900Z"
    }
   },
   "id": "82b3ef4eba92a209",
   "execution_count": 189
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'ids': 'dict' object cannot be converted to 'Sequence'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenized_train_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m12\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3782\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.decode\u001B[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001B[0m\n\u001B[0;32m   3779\u001B[0m \u001B[38;5;66;03m# Convert inputs to python lists\u001B[39;00m\n\u001B[0;32m   3780\u001B[0m token_ids \u001B[38;5;241m=\u001B[39m to_py_obj(token_ids)\n\u001B[1;32m-> 3782\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_decode\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3783\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3784\u001B[0m \u001B[43m    \u001B[49m\u001B[43mskip_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3785\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclean_up_tokenization_spaces\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclean_up_tokenization_spaces\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3786\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3787\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:625\u001B[0m, in \u001B[0;36mPreTrainedTokenizerFast._decode\u001B[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001B[0m\n\u001B[0;32m    623\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(token_ids, \u001B[38;5;28mint\u001B[39m):\n\u001B[0;32m    624\u001B[0m     token_ids \u001B[38;5;241m=\u001B[39m [token_ids]\n\u001B[1;32m--> 625\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtoken_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip_special_tokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    627\u001B[0m clean_up_tokenization_spaces \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    628\u001B[0m     clean_up_tokenization_spaces\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m clean_up_tokenization_spaces \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclean_up_tokenization_spaces\n\u001B[0;32m    631\u001B[0m )\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m clean_up_tokenization_spaces:\n",
      "\u001B[1;31mTypeError\u001B[0m: argument 'ids': 'dict' object cannot be converted to 'Sequence'"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T13:52:07.069159200Z",
     "start_time": "2024-05-23T13:51:58.109869900Z"
    }
   },
   "id": "f76671e433c66924",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset['train']]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset['train']]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe34416de1121bf2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "max_length = 120  # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b3e76e5d59b83b4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4121ff13e365288",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(tokenized_train_dataset['train'][1]['input_ids'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "272efb57d867178d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5673a5175e6f2638",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "eval_prompt = (\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "678f82c73601a318",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Init an eval tokenizer that doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0],\n",
    "                                skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47c8339c7d3e3ea2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from peft import PeftConfig\n",
    "\n",
    "adapter_model_id = \"ybelkada/opt-350m-lora\"\n",
    "peft_config = PeftConfig.from_pretrained(adapter_model_id)\n",
    "# to initiate with random weights\n",
    "peft_config.init_lora_weights = False\n",
    "\n",
    "model.add_adapter(peft_config)\n",
    "model.enable_adapters()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2441ddcd1a5181df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"###Character: \" + test_dataset['train'][200]['character'] + \"\\n  responded with: \" + test_dataset['train'][200][\n",
    "    'dialogue'] + \"\\n to what was said by: \" + test_dataset['train'][200]['response_to'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ab714e941181fd6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "570b93f08b1b61eb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddf562f6b54c4893",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fe694a164bb1ea8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6354fba6c3915b3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:  # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fcbe8317af8659a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = accelerator.prepare_model(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec3566a59128b91",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"own-finetune\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_val_dataset[\"train\"],\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=200,\n",
    "        learning_rate=2.5e-5,  # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,  # When to start reporting loss\n",
    "        logging_dir=\"./logs\",  # Directory for storing logs\n",
    "        save_strategy=\"steps\",  # Save the model checkpoint every logging step\n",
    "        save_steps=25,  # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\",  # Evaluate the model every logging step\n",
    "        eval_steps=25,  # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,\n",
    "        # Perform evaluation at the end of training         # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"  # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c48d66dfa4929c8f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea90e93a904c5d4a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"mistral-own-finetune/checkpoint-50\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e154dc87f95c4f41",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "eval_prompt = \"Start a conversation where Dutch van der Linde plans a new heist\"\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=280, repetition_penalty=1.15)[0],\n",
    "                                skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16f5ddad06c7fa1b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Rouge Score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bef0d5c5cee19e4f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "generated_dialogues = [\"Doctor:  I'm afraid you have tuberculosis. We need to start treatment right away.\",\n",
    "                       \"Arthur Morgan: Tuberculosis... That's a death sentence isn't it?\"]\n",
    "\n",
    "reference_dialogues = [\"Doctor: You got tuberculosis. I’m really sorry for you, son, it’s a hell of a thing.\",\n",
    "                       \"Arthur Morgan: Aah… What is it?\"]\n",
    "\n",
    "print(len(reference_dialogues))\n",
    "\n",
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "rouge_scores = rouge.get_scores(' '.join(generated_dialogues), ' '.join(reference_dialogues[0]))\n",
    "\n",
    "# Output the scores \n",
    "\n",
    "print(f\"ROUGE: {rouge_scores}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9c66b4e9da55ee4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "\n",
    "# Tokenize the reference and generated dialogues into words\n",
    "reference_dialogues = [\n",
    "    [\"Doctor:\", \"You\", \"got\", \"tuberculosis.\", \"I’m\", \"really\", \"sorry\", \"for\", \"you,\", \"son,\", \"it’s\", \"a\", \"hell\", \"of\", \"a\", \"thing.\"],\n",
    "    [\"Arthur\", \"Morgan:\", \"Aah…\", \"What\", \"is\", \"it?\"]\n",
    "]\n",
    "generated_dialogues = [\n",
    "    [\"Doctor:\", \"I'm\", \"afraid\", \"you\", \"have\", \"tuberculosis.\", \"We\", \"need\", \"to\", \"start\", \"treatment\", \"right\", \"away.\"],\n",
    "    [\"Arthur\", \"Morgan:\", \"Tuberculosis...\", \"That's\", \"a\", \"death\", \"sentence\", \"isn't\", \"it?\"]\n",
    "]\n",
    "\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = sentence_bleu(reference_dialogues, generated_dialogues)\n",
    "print(f\"BLEU: {bleu_score}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b738655740170ad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "728c8d2a5290e8c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
