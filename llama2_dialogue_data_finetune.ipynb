{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-06-16T09:20:05.932230Z",
     "start_time": "2024-06-16T09:20:03.487086900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ba7eb407d9545dda9add3f3d0c23bed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"json\", data_files=\"dataset_final_results/stratified_train.json\")\n",
    "val_dataset = load_dataset(\"json\", data_files=\"dataset_final_results/stratified_val.json\")\n",
    "test_dataset = load_dataset(\"json\", data_files=\"dataset_final_results/stratified_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f92a617057aac80",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:24:31.081176600Z",
     "start_time": "2024-06-15T22:24:31.073860200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['Condition', 'Line_of_dialogue', 'Response_to', 'Equipment', 'Tone', 'Speaker', 'Dialogue', 'Event', 'Result', 'Location', 'Race'],\n        num_rows: 1417\n    })\n})"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c6ecad2a2d2007",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:24:31.097224400Z",
     "start_time": "2024-06-15T22:24:31.081176600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['Condition', 'Line_of_dialogue', 'Response_to', 'Equipment', 'Tone', 'Speaker', 'Dialogue', 'Event', 'Result', 'Location', 'Race'],\n        num_rows: 175\n    })\n})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61a9af870c68ea6a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:24:31.099224300Z",
     "start_time": "2024-06-15T22:24:31.088490300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['Condition', 'Line_of_dialogue', 'Response_to', 'Equipment', 'Tone', 'Speaker', 'Dialogue', 'Event', 'Result', 'Location', 'Race'],\n        num_rows: 181\n    })\n})"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad8e9abba327408",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:24:36.224422600Z",
     "start_time": "2024-06-15T22:24:31.094223800Z"
    }
   },
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "131418b6535338bf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:24:36.231146300Z",
     "start_time": "2024-06-15T22:24:36.206229800Z"
    }
   },
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "\n",
    "\n",
    "    description = f\"\"\"The following text elaborates on what line of dialogue is used by an NPC in a certain event. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER> and the line used will be enclosed within <LINE> and </LINE>.\n",
    "\n",
    "\"\"\"\n",
    "    if example['Event'] == \"Greeting\":\n",
    "\n",
    "        description = f\"\"\"The following text describes a greeting exchange between the Player and an NPC. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, and the tone of the line will be enclosed within <TONE> and </TONE>.\n",
    "\n",
    "\"\"\"\n",
    "    elif example['Event'] == \"NPCs fighting over a Player's dropped item\":\n",
    "\n",
    "        description = f\"\"\"The following text describes an exchange where multiple NPCs are fighting over a Player's dropped item and one of them uses a line of dialogue. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, and the number of the current spoken line in the dialogue will be enclosed within <NUMBER> and </NUMBER>.\n",
    "\n",
    "\"\"\"\n",
    "    elif example['Condition'] == \"in combat\":\n",
    "\n",
    "        description = f\"\"\"The following text elaborates on which line of dialogue a friendly NPC uses when it is in combat. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>,the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, and  the condition will be enclosed within <CONDITION> and </CONDITION>.\n",
    "\n",
    "\"\"\"\n",
    "    elif example['Result'] is not None:\n",
    "\n",
    "        description = f\"\"\"The following text text elaborates on which line of dialogue is used by an NPC when the Player character tries to persuade them. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>,the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE> and the result of the event will be enclosed within <RESULT> and </RESULT> .\n",
    "\n",
    "\"\"\"\n",
    "    elif example['Race'] is not None:\n",
    "\n",
    "        description = f\"\"\"The following text describes the reaction of a Guard based on the Player's race. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, the race of the Player will be enclosed within <RACE> and </RACE>, and the condition, if there is one, will be enclosed within <CONDITION> and </CONDITION>.\n",
    "\n",
    "\"\"\"\n",
    "    elif example['Equipment'] is not None:\n",
    "\n",
    "        description = f\"\"\"The following text describes the reaction of a Guard based on the Player's equipment. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, the equipment of the Player will be enclosed within <EQUIPMENT> and </EQUIPMENT>, and the condition, if there is one, will be enclosed within <CONDITION> and </CONDITION>.\n",
    "\n",
    "\"\"\"\n",
    "    elif example['Location'] is not None:\n",
    "\n",
    "        description = f\"\"\"The following text describes a special interaction of a Guard based on the Player's location. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, the location of the Player will be enclosed within <LOCATION> and </LOCATION>, and the condition, if there is one, will be enclosed within <CONDITION> and </CONDITION>.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    elif example['Response_to'] is not None:\n",
    "\n",
    "        description = f\"\"\"The following text describes a part of a dialogue between and NPC and the Player in the case of a certain event. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, and the line that the speaker responds to, will be enclosed within <RESPONSE> and </RESPONSE>.\n",
    "\n",
    "\"\"\"\n",
    "    elif example['Condition'] is not None:\n",
    "\n",
    "        description = f\"\"\"The following text elaborates on a line of dialogue used by an NPC in a certain event under a condition. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, and the condition, will be enclosed within <CONDITION> and </CONDITION>.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    if example['Speaker'] == \"Any\":\n",
    "\n",
    "        npc_type = \"the NPC, that is of any type\"\n",
    "\n",
    "    elif \"Guard\" in example['Speaker']:\n",
    "\n",
    "        npc_type = f'the {example[\"Speaker\"]}'\n",
    "\n",
    "    elif \"trainer\" in example['Event']:\n",
    "\n",
    "        npc_type = f\"\"\"the trainer NPC, that is named {example['Speaker']}\"\"\"\n",
    "\n",
    "    elif example['Speaker'] == \"Housecarl\":\n",
    "\n",
    "        npc_type = \"the Housecarl\"\n",
    "\n",
    "    else:\n",
    "\n",
    "        npc_type = f'the NPC, that is the type {example[\"Speaker\"]}'\n",
    "\n",
    "\n",
    "\n",
    "    if example['Event'] == \"Greeting\":\n",
    "\n",
    "        return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of a <EVENT>{example['Event']}</EVENT>, between an NPC and the Player character, <SPEAKER>{npc_type}</SPEAKER> greets the Player, in a <TONE>{example['Tone']}</TONE> tone, using the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "\n",
    "    if example['Event'] == \"Goodbye\":\n",
    "\n",
    "        return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of a <EVENT>{example['Event']}</EVENT>, between an NPC and the Player character,<SPEAKER>{npc_type}</SPEAKER> tells their goodbyes to the Player using the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "\n",
    "    if example['Event'] == \"NPCs fighting over a Player's dropped item\":\n",
    "\n",
    "        return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of <EVENT>{example['Event']}</EVENT>, there can be up to 5 different NPCs arguing over an item that the Player character dropped and up to 2 bystander NPCs commenting on the situation. Up to five lines of dialogue can be exchanged between up to five different NPCs that are arguing and up to two lines of bystander dialogue can be used by up to two different bystander NPCs, meaning that the conversation ends after a maximum of 7 lines of dialogue have been said. In this case one of the NPCs that takes part in the arguing and is <SPEAKER>{npc_type}</SPEAKER>, says, as the <NUMBER>{example['Line_of_dialogue']}</NUMBER> line of the dialogue, the following line: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "    if example['Event'] == \"NPC asking for the Player's dropped armor\":\n",
    "\n",
    "        if example['Speaker'] == \"Player\":\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of an <EVENT>{example['Event']}</EVENT>, there is a conversation between the Player character and an NPC about the Player's dropped item.\n",
    "In this case in response to the NPC's previous line of dialogue: <RESPONSE>{example['Response_to']}</RESPONSE>,the <SPEAKER>Player</SPEAKER> character uses the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "        if example['Response_to'] is not None:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of an <EVENT>{example['Event']}</EVENT> there is a conversation between the Player character and an NPC about the Player's dropped item.\n",
    "In this case in response to the Player character's previous line of dialogue: <RESPONSE>{example['Response_to']}</RESPONSE>, <SPEAKER>{npc_type}</SPEAKER> uses the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "        else:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of an <EVENT>{example['Event']}</EVENT> there is a conversation between the Player character and an NPC about the Player's dropped item.\n",
    "In this case to initiate a conversation about the Player's dropped item, <SPEAKER>{npc_type}</SPEAKER> uses the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "    if example['Condition'] == \"in combat\":\n",
    "\n",
    "        return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when the Player character and a friendly NPC are <CONDITION>{example['Condition']}</CONDITION>, when <EVENT>{example['Event']}</EVENT>,<SPEAKER>{npc_type}</SPEAKER> uses the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "    if example['Result'] is not None:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when the Player character tries to check if an NPC of any type can be persuaded, when <EVENT>{example['Event']}</EVENT> and as a result </RESULT>{example['Result']}<RESULT>, the <SPEAKER>{npc_type}</SPEAKER> uses the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "    if example['Event'] == \"an NPC spots the Player character having an amulet of mara\":\n",
    "\n",
    "        if example['Speaker'] == \"Player\":\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when <EVENT>{example['Event']}</EVENT> an interaction begins between the two about the possibility of marriage.\n",
    "In this case in response to the the NPC's previous dialogue line: <RESPONSE>{example['Response_to']}</RESPONSE>, the <SPEAKER>Player</SPEAKER> character uses the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "        if example['Response_to'] is None:\n",
    "\n",
    "            return description +  f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when <EVENT>{example['Event']}</EVENT> an interaction begins between the two about the possibility of marriage.\n",
    "In this case to initiate the conversation about marriage, <SPEAKER>{npc_type}</SPEAKER> uses the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "        else:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when <EVENT>{example['Event']}</EVENT> an interaction begins between the two about the possibility of marriage.\n",
    "In this case in response to the the Player's previous dialogue line: <RESPONSE>{example['Response_to']}</RESPONSE>, <SPEAKER>{npc_type}</SPEAKER> uses the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "    if example['Race'] is not None:\n",
    "\n",
    "        if example['Condition'] is not None:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the race of the Player character, in the case of <EVENT>{example['Event']}</EVENT>, if the Player's race is <RACE>{example['Race']}</RACE> and <CONDITION>{example['Condition']}</CONDITION>, the <SPEAKER>Guard</SPEAKER> uses the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "        else:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the race of the Player character, so in the case of <EVENT>{example['Event']}</EVENT>, if the Player's race is <RACE>{example['Race']}</RACE>, the <SPEAKER>Guard</SPEAKER> uses the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "    if example['Equipment'] is not None:\n",
    "\n",
    "        if example['Condition'] is not None:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the equipment the Player character is holding or has equipped, so when in the case of a <EVENT>{example['Event']}</EVENT> and <CONDITION>{example['Condition']}</CONDITION>, to react to the Player's <EQUIPMENT>{example['Equipment']}</EQUIPMENT>, the <SPEAKER>Guard</SPEAKER> uses the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "        else:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the equipment the Player character is holding or has equipped, so when in the case of a <EVENT>{example['Event']}</EVENT>, to react to the Player's <EQUIPMENT>{example['Equipment']}</EQUIPMENT>, the <SPEAKER>Guard</SPEAKER> uses the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "    if example['Location'] is not None:\n",
    "\n",
    "        if example['Condition'] is not None:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, <EVENT>Town Guards have special interactions with the Player character that are location based</EVENT>, meaning that the Guards sometimes interact with the Player using town specific dialogue.\n",
    "In this case in the town of <LOCATION>{example['Location']}</LOCATION> and on the condition that <CONDITION>{example['Condition']}</CONDITION>, a <SPEAKER>Guard</SPEAKER>, when the Player character interacts with them, uses the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "        else:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, <EVENT>Town Guards have special interactions with the Player character that are location based</EVENT>, meaning that the Guards sometimes interact with the Player using town specific dialogue.\n",
    "In this case in the town of <LOCATION>{example['Location']}</LOCATION>, a <SPEAKER>Guard</SPEAKER>, when the Player character interacts with them, uses the following line of dialogue: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "    if example['Condition'] is not None:\n",
    "\n",
    "          return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of <EVENT>{example['Event']}</EVENT> and on the condition that <CONDITION>{example['Condition']}</CONDITION>, <SPEAKER>{npc_type}</SPEAKER>, says the following line to the Player character: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\"\n",
    "\n",
    "    return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of <EVENT>{example['Event']}</EVENT>, <SPEAKER>{npc_type}</SPEAKER>, says the following line to the Player character: <LINE>{example['Dialogue']}</LINE>.\n",
    "<END>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Explicitly setting the token\n",
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:24:36.255151900Z",
     "start_time": "2024-06-15T22:24:36.222422100Z"
    }
   },
   "id": "a7010b90e0c1f23",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "380cd97b582df263",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:24:37.207741900Z",
     "start_time": "2024-06-15T22:24:36.229146Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoConfig\n",
    "config = AutoConfig.from_pretrained(\"meta-llama/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "base_model_id = \"meta-llama/Llama-2-7b-hf\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:24:37.212247300Z",
     "start_time": "2024-06-15T22:24:37.207741900Z"
    }
   },
   "id": "d632f344ba9aabd4",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:24:37.224071300Z",
     "start_time": "2024-06-15T22:24:37.211247200Z"
    }
   },
   "id": "9a7f272e3e8e4ecc",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe25a8ccaa7f4da09c86d05b79f7f443"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config,config=config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:24:59.506805500Z",
     "start_time": "2024-06-15T22:24:37.219070Z"
    }
   },
   "id": "5e3d64226cbbc1df",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe4ef3ec3c37141",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:24:59.520545200Z",
     "start_time": "2024-06-15T22:24:59.510540700Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(formatting_func(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a540269d58fd473",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:24:59.611296600Z",
     "start_time": "2024-06-15T22:24:59.512543300Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c4e0d60cc136063",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:24:59.651370300Z",
     "start_time": "2024-06-15T22:24:59.613297Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_val_dataset = val_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe34416de1121bf2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:25:00.775086600Z",
     "start_time": "2024-06-15T22:24:59.653369600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1592\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset['train']]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset['train']]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "805a339c5f8c1dbd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:25:01.289624800Z",
     "start_time": "2024-06-15T22:25:00.772085400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 235.16796047988709\n",
      "95th percentile: 299.0\n",
      "Max length: 382\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lengths = [len(x['input_ids']) for x in tokenized_train_dataset['train']]\n",
    "\n",
    "print(f\"Mean: {np.mean(lengths)}\")\n",
    "\n",
    "# Calculate the 95th percentile\n",
    "print(f\"95th percentile: {np.percentile(lengths, 95)}\")\n",
    "\n",
    "# Calculate the max length\n",
    "print(f\"Max length: {np.max(lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b3e76e5d59b83b4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:25:01.294625900Z",
     "start_time": "2024-06-15T22:25:01.289624800Z"
    }
   },
   "outputs": [],
   "source": [
    "max_length = 382  # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4121ff13e365288",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:25:01.371984600Z",
     "start_time": "2024-06-15T22:25:01.292625400Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_val_dataset = val_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5673a5175e6f2638",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:25:02.694496700Z",
     "start_time": "2024-06-15T22:25:01.371984600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1592\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "678f82c73601a318",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T20:41:33.204766100Z",
     "start_time": "2024-06-15T20:41:33.150751800Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_prompt = (f\"\"\"The following text describes a greeting exchange between the Player and an NPC. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, and the tone of the line will be enclosed within <TONE> and </TONE>.\n",
    "\n",
    "Please remember to generate the dialogue inside the following <LINE> and </LINE> tags inside the provided text below,for example replace <LINE> </LINE> with <LINE>Missing Dialogue</LINE>.\n",
    "\n",
    "<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of a <EVENT>Greeting</EVENT>, between an NPC and the Player character, <SPEAKER>FemaleCoward</SPEAKER> greets the Player, in a <TONE>Friendly</TONE> tone, with the following line of dialogue: <LINE> </LINE>.\n",
    "<END>\n",
    "\n",
    "Answer:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47c8339c7d3e3ea2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T20:41:39.669531500Z",
     "start_time": "2024-06-15T20:41:33.432436700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following text describes a greeting exchange between the Player and an NPC. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, and the tone of the line will be enclosed within <TONE> and </TONE>.\n",
      "\n",
      "Please remember to generate the dialogue inside the following <LINE> and </LINE> tags inside the provided text below,for example replace <LINE> </LINE> with <LINE>Missing Dialogue</LINE>.\n",
      "\n",
      "<START>\n",
      "In the world of Skyrim from the game Elder Scrolls V, in the event of a <EVENT>Greeting</EVENT>, between an NPC and the Player character, <SPEAKER>FemaleCoward</SPEAKER> greets the Player, in a <TONE>Friendly</TONE> tone, with the following line of dialogue: <LINE> </LINE>.\n",
      "<END>\n",
      "\n",
      "Answer:\n",
      "\\begin{itemize}\n",
      "\\item Missing Line Of Greetings - Female Cowards  Friendliness (0/1) : \"Hello\" or similar friendly-neutral term for those who do not know each other well yet; this is usually followed by questions about health (\"Are you feeling alright?\") if it has been some time since they last saw one another\n"
     ]
    }
   ],
   "source": [
    "# Init an eval tokenizer that doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=300, repetition_penalty=1.45)[0],\n",
    "                                skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "570b93f08b1b61eb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:25:02.843111Z",
     "start_time": "2024-06-15T22:25:02.693496400Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddf562f6b54c4893",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:25:02.848314700Z",
     "start_time": "2024-06-15T22:25:02.844111300Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1116078209be7ce6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:25:02.914530500Z",
     "start_time": "2024-06-15T22:25:02.848314700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fe694a164bb1ea8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:25:04.261667600Z",
     "start_time": "2024-06-15T22:25:02.857186100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 128974848 || all params: 3629387776 || trainable%: 3.5536254586206\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj,\"\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    use_rslora=True,\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6354fba6c3915b3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:25:04.277082400Z",
     "start_time": "2024-06-15T22:25:04.262667800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): LlamaForCausalLM(\n",
      "      (model): LlamaModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x LlamaDecoderLayer(\n",
      "            (self_attn): LlamaSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=11008, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=11008, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): LlamaRMSNorm()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fcbe8317af8659a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:25:04.327170100Z",
     "start_time": "2024-06-15T22:25:04.275081600Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:  # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec3566a59128b91",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T22:25:04.330170800Z",
     "start_time": "2024-06-15T22:25:04.284984500Z"
    }
   },
   "outputs": [],
   "source": [
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c48d66dfa4929c8f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T23:35:17.695167Z",
     "start_time": "2024-06-15T22:37:29.113796100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pumukl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='51' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  51/2126 02:29 < 1:45:23, 0.33 it/s, Epoch 0.07/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='101' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 101/2126 06:08 < 2:05:41, 0.27 it/s, Epoch 0.14/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='151' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 151/2126 09:45 < 2:09:25, 0.25 it/s, Epoch 0.21/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.180100</td>\n      <td>0.233338</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='201' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 201/2126 13:23 < 2:09:33, 0.25 it/s, Epoch 0.28/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.180100</td>\n      <td>0.233338</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.202700</td>\n      <td>0.200755</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='251' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 251/2126 17:00 < 2:08:03, 0.24 it/s, Epoch 0.35/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.180100</td>\n      <td>0.233338</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.202700</td>\n      <td>0.200755</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.178700</td>\n      <td>0.183751</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='301' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 301/2126 20:35 < 2:05:41, 0.24 it/s, Epoch 0.42/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.180100</td>\n      <td>0.233338</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.202700</td>\n      <td>0.200755</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.178700</td>\n      <td>0.183751</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.173300</td>\n      <td>0.171825</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='351' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 351/2126 24:10 < 2:02:58, 0.24 it/s, Epoch 0.49/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.180100</td>\n      <td>0.233338</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.202700</td>\n      <td>0.200755</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.178700</td>\n      <td>0.183751</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.173300</td>\n      <td>0.171825</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.161000</td>\n      <td>0.166915</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='401' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 401/2126 27:45 < 2:00:02, 0.24 it/s, Epoch 0.56/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.180100</td>\n      <td>0.233338</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.202700</td>\n      <td>0.200755</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.178700</td>\n      <td>0.183751</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.173300</td>\n      <td>0.171825</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.161000</td>\n      <td>0.166915</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.144100</td>\n      <td>0.163881</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='451' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 451/2126 31:21 < 1:56:57, 0.24 it/s, Epoch 0.63/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.180100</td>\n      <td>0.233338</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.202700</td>\n      <td>0.200755</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.178700</td>\n      <td>0.183751</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.173300</td>\n      <td>0.171825</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.161000</td>\n      <td>0.166915</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.144100</td>\n      <td>0.163881</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.141500</td>\n      <td>0.155863</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='501' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 501/2126 34:56 < 1:53:46, 0.24 it/s, Epoch 0.71/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.180100</td>\n      <td>0.233338</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.202700</td>\n      <td>0.200755</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.178700</td>\n      <td>0.183751</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.173300</td>\n      <td>0.171825</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.161000</td>\n      <td>0.166915</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.144100</td>\n      <td>0.163881</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.141500</td>\n      <td>0.155863</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.133500</td>\n      <td>0.152969</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='551' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 551/2126 38:31 < 1:50:31, 0.24 it/s, Epoch 0.78/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.180100</td>\n      <td>0.233338</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.202700</td>\n      <td>0.200755</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.178700</td>\n      <td>0.183751</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.173300</td>\n      <td>0.171825</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.161000</td>\n      <td>0.166915</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.144100</td>\n      <td>0.163881</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.141500</td>\n      <td>0.155863</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.133500</td>\n      <td>0.152969</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.138800</td>\n      <td>0.148526</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='601' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 601/2126 42:06 < 1:47:12, 0.24 it/s, Epoch 0.85/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.180100</td>\n      <td>0.233338</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.202700</td>\n      <td>0.200755</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.178700</td>\n      <td>0.183751</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.173300</td>\n      <td>0.171825</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.161000</td>\n      <td>0.166915</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.144100</td>\n      <td>0.163881</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.141500</td>\n      <td>0.155863</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.133500</td>\n      <td>0.152969</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.138800</td>\n      <td>0.148526</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.123600</td>\n      <td>0.145410</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='651' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 651/2126 45:41 < 1:43:50, 0.24 it/s, Epoch 0.92/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.180100</td>\n      <td>0.233338</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.202700</td>\n      <td>0.200755</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.178700</td>\n      <td>0.183751</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.173300</td>\n      <td>0.171825</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.161000</td>\n      <td>0.166915</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.144100</td>\n      <td>0.163881</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.141500</td>\n      <td>0.155863</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.133500</td>\n      <td>0.152969</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.138800</td>\n      <td>0.148526</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.123600</td>\n      <td>0.145410</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.129900</td>\n      <td>0.142724</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='701' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 701/2126 49:15 < 1:40:26, 0.24 it/s, Epoch 0.99/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.180100</td>\n      <td>0.233338</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.202700</td>\n      <td>0.200755</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.178700</td>\n      <td>0.183751</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.173300</td>\n      <td>0.171825</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.161000</td>\n      <td>0.166915</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.144100</td>\n      <td>0.163881</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.141500</td>\n      <td>0.155863</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.133500</td>\n      <td>0.152969</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.138800</td>\n      <td>0.148526</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.123600</td>\n      <td>0.145410</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.129900</td>\n      <td>0.142724</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.131500</td>\n      <td>0.141237</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='751' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 751/2126 52:49 < 1:36:58, 0.24 it/s, Epoch 1.06/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.180100</td>\n      <td>0.233338</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.202700</td>\n      <td>0.200755</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.178700</td>\n      <td>0.183751</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.173300</td>\n      <td>0.171825</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.161000</td>\n      <td>0.166915</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.144100</td>\n      <td>0.163881</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.141500</td>\n      <td>0.155863</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.133500</td>\n      <td>0.152969</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.138800</td>\n      <td>0.148526</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.123600</td>\n      <td>0.145410</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.129900</td>\n      <td>0.142724</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.131500</td>\n      <td>0.141237</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.088000</td>\n      <td>0.145517</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='801' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 801/2126 56:24 < 1:33:32, 0.24 it/s, Epoch 1.13/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.180100</td>\n      <td>0.233338</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.202700</td>\n      <td>0.200755</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.178700</td>\n      <td>0.183751</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.173300</td>\n      <td>0.171825</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.161000</td>\n      <td>0.166915</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.144100</td>\n      <td>0.163881</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.141500</td>\n      <td>0.155863</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.133500</td>\n      <td>0.152969</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.138800</td>\n      <td>0.148526</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.123600</td>\n      <td>0.145410</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.129900</td>\n      <td>0.142724</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.131500</td>\n      <td>0.141237</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.088000</td>\n      <td>0.145517</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.084400</td>\n      <td>0.143891</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='806' max='2126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 806/2126 57:42 < 1:34:44, 0.23 it/s, Epoch 1.14/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.249900</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.214800</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.180100</td>\n      <td>0.233338</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.202700</td>\n      <td>0.200755</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.178700</td>\n      <td>0.183751</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.173300</td>\n      <td>0.171825</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.161000</td>\n      <td>0.166915</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.144100</td>\n      <td>0.163881</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.141500</td>\n      <td>0.155863</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.133500</td>\n      <td>0.152969</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.138800</td>\n      <td>0.148526</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.123600</td>\n      <td>0.145410</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.129900</td>\n      <td>0.142724</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.131500</td>\n      <td>0.141237</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.088000</td>\n      <td>0.145517</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.084400</td>\n      <td>0.143891</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 35\u001B[0m\n\u001B[0;32m      8\u001B[0m trainer \u001B[38;5;241m=\u001B[39m transformers\u001B[38;5;241m.\u001B[39mTrainer(\n\u001B[0;32m      9\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m     10\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mtokenized_train_dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     31\u001B[0m     data_collator\u001B[38;5;241m=\u001B[39mtransformers\u001B[38;5;241m.\u001B[39mDataCollatorForLanguageModeling(tokenizer, mlm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[0;32m     32\u001B[0m )\n\u001B[0;32m     34\u001B[0m model\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_cache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m  \u001B[38;5;66;03m# silence the warnings. Please re-enable for inference!\u001B[39;00m\n\u001B[1;32m---> 35\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:1624\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1622\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   1623\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1624\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1625\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1626\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1627\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1628\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1629\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:1961\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   1958\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_begin(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[0;32m   1960\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39maccumulate(model):\n\u001B[1;32m-> 1961\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1963\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1964\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[0;32m   1965\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_tpu_available()\n\u001B[0;32m   1966\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[0;32m   1967\u001B[0m ):\n\u001B[0;32m   1968\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[0;32m   1969\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:2911\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[1;34m(self, model, inputs)\u001B[0m\n\u001B[0;32m   2909\u001B[0m         scaled_loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m   2910\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2911\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2913\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mdetach() \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mgradient_accumulation_steps\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\accelerator.py:2013\u001B[0m, in \u001B[0;36mAccelerator.backward\u001B[1;34m(self, loss, **kwargs)\u001B[0m\n\u001B[0;32m   2011\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2012\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2013\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    521\u001B[0m     )\n\u001B[1;32m--> 522\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    524\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 266\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "project = \"NPC-finetune\"\n",
    "base_model_name = \"llama2\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_val_dataset[\"train\"],\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=2126,\n",
    "        learning_rate=2.5e-5,  # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,  # When to start reporting loss\n",
    "        logging_dir=\"./logs\",  # Directory for storing logs\n",
    "        save_strategy=\"steps\",  # Save the model checkpoint every logging step\n",
    "        save_steps=50,  # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\",  # Evaluate the model every logging step\n",
    "        eval_steps=50,  # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,\n",
    "        max_grad_norm=1.0,\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    step    loss  eval_loss\n0     50  0.2499   0.305938\n1    100  0.2148   0.261423\n2    150  0.1801   0.233338\n3    200  0.2027   0.200755\n4    250  0.1787   0.183751\n5    300  0.1733   0.171825\n6    350  0.1610   0.166915\n7    400  0.1441   0.163881\n8    450  0.1415   0.155863\n9    500  0.1335   0.152969\n10   550  0.1388   0.148526\n11   600  0.1236   0.145410\n12   650  0.1299   0.142724\n13   700  0.1315   0.141237\n14   750  0.0880   0.145517\n15   800  0.0844   0.143891",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>step</th>\n      <th>loss</th>\n      <th>eval_loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50</td>\n      <td>0.2499</td>\n      <td>0.305938</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>0.2148</td>\n      <td>0.261423</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150</td>\n      <td>0.1801</td>\n      <td>0.233338</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>200</td>\n      <td>0.2027</td>\n      <td>0.200755</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>250</td>\n      <td>0.1787</td>\n      <td>0.183751</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>300</td>\n      <td>0.1733</td>\n      <td>0.171825</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>350</td>\n      <td>0.1610</td>\n      <td>0.166915</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>400</td>\n      <td>0.1441</td>\n      <td>0.163881</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>450</td>\n      <td>0.1415</td>\n      <td>0.155863</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>500</td>\n      <td>0.1335</td>\n      <td>0.152969</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>550</td>\n      <td>0.1388</td>\n      <td>0.148526</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>600</td>\n      <td>0.1236</td>\n      <td>0.145410</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>650</td>\n      <td>0.1299</td>\n      <td>0.142724</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>700</td>\n      <td>0.1315</td>\n      <td>0.141237</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>750</td>\n      <td>0.0880</td>\n      <td>0.145517</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>800</td>\n      <td>0.0844</td>\n      <td>0.143891</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate the diagrams for the training\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load from the output_dir the last checkpoints trainer state, validation loss and training loss\n",
    "df = pd.read_json(output_dir + \"/checkpoint-800/trainer_state.json\")\n",
    "\n",
    "df = df['log_history']\n",
    "\n",
    "#drop every third row\n",
    "df = df.drop(df.index[::3])\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# conbine the dictionaries of every two rows\n",
    "df = pd.DataFrame([{**df[i], **df[i + 1]} for i in range(0, len(df), 2)])\n",
    "\n",
    "# keep only the step, training loss and validation loss columns\n",
    "df = df[['step', 'loss', 'eval_loss']]\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T17:40:39.292011700Z",
     "start_time": "2024-06-27T17:40:39.249063700Z"
    }
   },
   "id": "21162dc4137c952e",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(df[\"step\"], df[\"loss\"], label=\"Training Loss\", marker='o')\n",
    "\n",
    "plt.plot(df[\"step\"], df[\"eval_loss\"], label=\"Validation Loss\", marker='o')\n",
    "\n",
    "plt.title(\"Training and Validation Loss Over Steps\")\n",
    "\n",
    "plt.xlabel(\"Step\")\n",
    "\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T17:41:21.438852300Z",
     "start_time": "2024-06-27T17:41:21.305919400Z"
    }
   },
   "id": "ac09349239546ce2",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dac0fcdfa85d463797d7e90e9a736d8f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"meta-llama/Llama-2-7b-hf\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Llama2, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T05:28:47.800840900Z",
     "start_time": "2024-06-16T05:28:16.522886500Z"
    }
   },
   "id": "ea90e93a904c5d4a",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e154dc87f95c4f41",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T05:28:53.971197800Z",
     "start_time": "2024-06-16T05:28:50.845650700Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"llama2-NPC-finetune/checkpoint-700\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following text text elaborates on which line of dialogue is used by an NPC when the Player character tries to persuade them. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>,the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE> and the result of the event will be enclosed within <RESULT> and </RESULT>. Generate the missing dialogue line between the <LINE> and </LINE> tags inside the provided text.\n",
      "\n",
      "<START>\n",
      "In the world of Skyrim from the game Elder Scrolls V, when the Player character tries to check if an NPC of any type can be persuaded, when <EVENT>rejecting the Player's intimidation</EVENT>and as a result </RESULT>a brawl begins<RESULT>, the <SPEAKER>NPC that is of any type</SPEAKER> uses the following line of dialogue: \n",
      "<END>\n",
      "\n",
      "Please remember to generate the line of dialogue used by the NPC based on the given context and not a description of what took place.\n",
      "\n",
      "Generated dialogue:\n",
      "\n",
      "<LINE>I don't think so.</LINE>\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = (f\"\"\"\n",
    "The following text text elaborates on which line of dialogue is used by an NPC when the Player character tries to persuade them. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>,the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE> and the result of the event will be enclosed within <RESULT> and </RESULT>. Generate the missing dialogue line between the <LINE> and </LINE> tags inside the provided text.\n",
    "\n",
    "<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when the Player character tries to check if an NPC of any type can be persuaded, when <EVENT>rejecting the Player's intimidation</EVENT>and as a result </RESULT>a brawl begins<RESULT>, the <SPEAKER>NPC that is of any type</SPEAKER> uses the following line of dialogue: \n",
    "<END>\n",
    "\n",
    "Please remember to generate the line of dialogue used by the NPC based on the given context and not a description of what took place.\n",
    "\n",
    "Generated dialogue:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    ")\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=750, repetition_penalty=1.25,pad_token_id=2, temperature=0.3, top_p = 0.65)[0],\n",
    "                                skip_special_tokens=True))\n",
    "    #save the results to a list\n",
    "    answer = eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=750, repetition_penalty=1.25,pad_token_id=2, temperature=0.3, top_p = 0.65)[0],\n",
    "                                skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T07:13:55.050948700Z",
     "start_time": "2024-06-16T07:13:51.294236Z"
    }
   },
   "id": "16f5ddad06c7fa1b",
   "execution_count": 141
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluation_func(example):\n",
    "\n",
    "    description = f\"\"\"The following text elaborates on what line of dialogue is used by an NPC in a certain event. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER> and the line used will be enclosed within <LINE> and </LINE>. Generate the missing dialogue line between the <LINE> and </LINE> tags inside the provided text.\n",
    "    \n",
    "\"\"\"\n",
    "    if example['Event'] == \"Greeting\":\n",
    "\n",
    "        description = f\"\"\"The following text describes a greeting exchange between the Player and an NPC. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, and the tone of the line will be enclosed within <TONE> and </TONE>.Generate the missing dialogue line between the <LINE> and </LINE> tags inside the provided text.\n",
    "\n",
    "\"\"\"\n",
    "    elif example['Event'] == \"NPCs fighting over a Player's dropped item\":\n",
    "\n",
    "        description = f\"\"\"The following text describes an exchange where multiple NPCs are fighting over a Player's dropped item and one of them uses a line of dialogue. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, and the number of the current spoken line in the dialogue will be enclosed within <NUMBER> and </NUMBER>. Generate the missing dialogue line between the <LINE> and </LINE> tags inside the provided text.\n",
    "\n",
    "\"\"\"\n",
    "    elif example['Condition'] == \"in combat\":\n",
    "\n",
    "        description = f\"\"\"The following text elaborates on which line of dialogue a friendly NPC uses when it is in combat. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>,the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, and  the condition will be enclosed within <CONDITION> and </CONDITION>. Generate the missing dialogue line between the <LINE> and </LINE> tags. Generate the missing dialogue line between the <LINE> and </LINE> tags inside the provided text.\n",
    "\n",
    "\"\"\"\n",
    "    elif example['Result'] is not None:\n",
    "\n",
    "        description = f\"\"\"The following text text elaborates on which line of dialogue is used by an NPC when the Player character tries to persuade them. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>,the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE> and the result of the event will be enclosed within <RESULT> and </RESULT>. Generate the missing dialogue line between the <LINE> and </LINE> tags inside the provided text.\n",
    "\n",
    "\"\"\"\n",
    "    elif example['Race'] is not None:\n",
    "\n",
    "        description = f\"\"\"The following text describes the reaction of a Guard based on the Player's race. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, the race of the Player will be enclosed within <RACE> and </RACE>, and the condition, if there is one, will be enclosed within <CONDITION> and </CONDITION>. Generate the missing dialogue line between the <LINE> and </LINE> tags inside the provided text.\n",
    "\n",
    "\"\"\"\n",
    "    elif example['Equipment'] is not None:\n",
    "\n",
    "        description = f\"\"\"The following text describes the reaction of a Guard based on the Player's equipment. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, the equipment of the Player will be enclosed within <EQUIPMENT> and </EQUIPMENT>, and the condition, if there is one, will be enclosed within <CONDITION> and </CONDITION>. GGenerate the missing dialogue line between the <LINE> and </LINE> tags inside the provided text.\n",
    "\n",
    "\"\"\"\n",
    "    elif example['Location'] is not None:\n",
    "\n",
    "        description = f\"\"\"The following text describes a special interaction of a Guard based on the Player's location. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, the location of the Player will be enclosed within <LOCATION> and </LOCATION>, and the condition, if there is one, will be enclosed within <CONDITION> and </CONDITION>. Generate the missing dialogue line between the <LINE> and </LINE> tags inside the provided text.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    elif example['Response_to'] is not None:\n",
    "\n",
    "        description = f\"\"\"The following text describes a part of a dialogue between and NPC and the Player in the case of a certain event. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, and the line that the speaker responds to, will be enclosed within <RESPONSE> and </RESPONSE>. Generate the missing dialogue line between the <LINE> and </LINE> tags inside the provided text.\n",
    "\n",
    "\"\"\"\n",
    "    elif example['Condition'] is not None:\n",
    "\n",
    "        description = f\"\"\"The following text elaborates on a line of dialogue used by an NPC in a certain event under a condition. The text will be enclosed within <START> and <END>. There are specific rules that apply only to the text: the event will be enclosed within <EVENT> and </EVENT>, the type of speaker will be enclosed within <SPEAKER> and </SPEAKER>, the line used will be enclosed within <LINE> and </LINE>, and the condition, will be enclosed within <CONDITION> and </CONDITION>. Generate the missing dialogue line between the <LINE> and </LINE> tags inside the provided text.\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    if example['Speaker'] == \"Any\":\n",
    "\n",
    "        npc_type = \"the NPC, that is of any type\"\n",
    "\n",
    "    elif \"Guard\" in example['Speaker']:\n",
    "\n",
    "        npc_type = f'the {example[\"Speaker\"]}'\n",
    "\n",
    "    elif \"trainer\" in example['Event']:\n",
    "\n",
    "        npc_type = f\"\"\"the trainer NPC, that is named {example['Speaker']}\"\"\"\n",
    "\n",
    "    elif example['Speaker'] == \"Housecarl\":\n",
    "\n",
    "        npc_type = \"the Housecarl\"\n",
    "\n",
    "    else:\n",
    "\n",
    "        npc_type = f'the NPC, that is the type {example[\"Speaker\"]}'\n",
    "\n",
    "\n",
    "\n",
    "    if example['Event'] == \"Greeting\":\n",
    "\n",
    "        return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of a <EVENT>{example['Event']}</EVENT>, between an NPC and the Player character, <SPEAKER>{npc_type}</SPEAKER> greets the Player, in a <TONE>{example['Tone']}</TONE> tone, using the following line of dialogue: \n",
    "<END>\n",
    "\n",
    "Please remember to generate the line of dialogue used by the NPC.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    if example['Event'] == \"Goodbye\":\n",
    "\n",
    "        return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of a <EVENT>{example['Event']}</EVENT>, between an NPC and the Player character,<SPEAKER>{npc_type}</SPEAKER> tells their goodbyes to the Player using the following line of dialogue: \n",
    "<END>\n",
    "\n",
    "The NPC must always say a dialogue line related to the context, it cannot say nothing.\n",
    "\n",
    "Please remember to generate the line of dialogue used by the NPC.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    if example['Event'] == \"NPCs fighting over a Player's dropped item\":\n",
    "\n",
    "        return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of <EVENT>{example['Event']}</EVENT>, there can be up to 5 different NPCs arguing over an item that the Player character dropped and up to 2 bystander NPCs commenting on the situation. Up to five lines of dialogue can be exchanged between up to five different NPCs that are arguing and up to two lines of bystander dialogue can be used by up to two different bystander NPCs, meaning that the conversation ends after a maximum of 7 lines of dialogue have been said. In this case one of the NPCs that takes part in the arguing and is <SPEAKER>{npc_type}</SPEAKER>, says, as the <NUMBER>{example['Line_of_dialogue']}</NUMBER> line of the dialogue, the following line:\n",
    "<END>\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Please remember to generate the line of dialogue used by the NPC based on the given context and not a description of what took place.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "    if example['Event'] == \"NPC asking for the Player's dropped armor\":\n",
    "\n",
    "        if example['Speaker'] == \"Player\":\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of an <EVENT>{example['Event']}</EVENT>, there is a conversation between the Player character and an NPC about the Player's dropped item.\n",
    "In this case in response to the NPC's previous line of dialogue: <RESPONSE>{example['Response_to']}</RESPONSE>,the <SPEAKER>Player</SPEAKER> character uses the following line of dialogue:\n",
    "<END>\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Please remember to generate the line of dialogue used by the Player.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "        if example['Response_to'] is not None:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of an <EVENT>{example['Event']}</EVENT> there is a conversation between the Player character and an NPC about the Player's dropped item.\n",
    "In this case in response to the Player character's previous line of dialogue: <RESPONSE>{example['Response_to']}</RESPONSE>, <SPEAKER>{npc_type}</SPEAKER> uses the following line of dialogue: <LINE> </LINE>.\n",
    "<END>\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Please remember to generate the line of dialogue used by the NPC.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "        else:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of an <EVENT>{example['Event']}</EVENT> there is a conversation between the Player character and an NPC about the Player's dropped item.\n",
    "In this case to initiate a conversation about the Player's dropped item, <SPEAKER>{npc_type}</SPEAKER> uses the following line of dialogue: <LINE> </LINE>.\n",
    "<END>\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Please remember to generate the line of dialogue used by the NPC.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "    if example['Condition'] == \"in combat\":\n",
    "\n",
    "        return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when the Player character and a friendly NPC are <CONDITION>{example['Condition']}</CONDITION>, when <EVENT>{example['Event']}</EVENT>,<SPEAKER>{npc_type}</SPEAKER> uses the following line of dialogue:\n",
    "<END>\n",
    "\n",
    "Please remember to generate the line of dialogue used by the NPC based on the given context and not a description of what took place.\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "    if example['Result'] is not None:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when the Player character tries to check if an NPC of any type can be persuaded, when <EVENT>{example['Event']}</EVENT> and as a result </RESULT>{example['Result']}<RESULT>, <SPEAKER>{npc_type}</SPEAKER> uses the following line of dialogue:\n",
    "<END>\n",
    "\n",
    "Please remember to generate the line of dialogue used by the NPC, based on the given context and not a description of what took place.\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "    if example['Event'] == \"an NPC spots the Player character having an amulet of mara\":\n",
    "\n",
    "        if example['Speaker'] == \"Player\":\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when <EVENT>{example['Event']}</EVENT> an interaction begins between the two about the possibility of marriage.\n",
    "In this case in response to the the NPC's previous dialogue line: <RESPONSE>{example['Response_to']}</RESPONSE>, the <SPEAKER>Player</SPEAKER> character uses the following line of dialogue:\n",
    "<END>\n",
    "\n",
    "Please remember to generate the line of dialogue used by the Player.\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "        if example['Response_to'] is None:\n",
    "\n",
    "            return description +  f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when <EVENT>{example['Event']}</EVENT> an interaction begins between the two about the possibility of marriage.\n",
    "In this case to initiate the conversation about marriage, <SPEAKER>{npc_type}</SPEAKER> uses the following line of dialogue:\n",
    "<END>\n",
    "\n",
    "Please remember to generate the line of dialogue used by the NPC.\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "        else:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, when <EVENT>{example['Event']}</EVENT> an interaction begins between the two about the possibility of marriage.\n",
    "In this case in response to the the Player's previous dialogue line: <RESPONSE>{example['Response_to']}</RESPONSE>, <SPEAKER>{npc_type}</SPEAKER> uses the following line of dialogue:\n",
    "<END>\n",
    "\n",
    "Please remember to generate the line of dialogue used by the NPC.\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "    if example['Race'] is not None:\n",
    "\n",
    "        if example['Condition'] is not None:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the race of the Player character, in the case of <EVENT>{example['Event']}</EVENT>, if the Player's race is <RACE>{example['Race']}</RACE> and <CONDITION>{example['Condition']}</CONDITION>, the <SPEAKER>Guard</SPEAKER> uses the following line of dialogue:\n",
    "<END>\n",
    "\n",
    "Please remember to generate the line of dialogue used by the Guard.\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "        else:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the race of the Player character, so in the case of <EVENT>{example['Event']}</EVENT>, if the Player's race is <RACE>{example['Race']}</RACE>, the <SPEAKER>Guard</SPEAKER> uses the following line of dialogue:\n",
    "<END>\n",
    "\n",
    "Please remember to generate the line of dialogue used by the Guard.\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "    if example['Equipment'] is not None:\n",
    "\n",
    "        if example['Condition'] is not None:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the equipment the Player character is holding or has equipped, so when in the case of a <EVENT>{example['Event']}</EVENT> and <CONDITION>{example['Condition']}</CONDITION>, to react to the Player's <EQUIPMENT>{example['Equipment']}</EQUIPMENT>, the <SPEAKER>Guard</SPEAKER> uses the following line of dialogue:\n",
    "<END>\n",
    "\n",
    "Please remember to generate the line of dialogue used by the Guard.\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "        else:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, Town Guards have special reactions to the equipment the Player character is holding or has equipped, so when in the case of a <EVENT>{example['Event']}</EVENT>, to react to the Player's <EQUIPMENT>{example['Equipment']}</EQUIPMENT>, the <SPEAKER>Guard</SPEAKER> uses the following line of dialogue:\n",
    "<END>\n",
    "\n",
    "Please remember to generate the line of dialogue used by the Guard.\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "    if example['Location'] is not None:\n",
    "\n",
    "        if example['Condition'] is not None:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, <EVENT>Town Guards have special interactions with the Player character that are location based</EVENT>, meaning that the Guards sometimes interact with the Player using town specific dialogue.\n",
    "In this case in the town of <LOCATION>{example['Location']}</LOCATION> and on the condition that <CONDITION>{example['Condition']}</CONDITION>, a <SPEAKER>Guard</SPEAKER>, when the Player character interacts with them, uses the following line of dialogue:\n",
    "<END>\n",
    "\n",
    "Please remember to generate the line of dialogue used by the Guard.\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "        else:\n",
    "\n",
    "            return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, <EVENT>Town Guards have special interactions with the Player character that are location based</EVENT>, meaning that the Guards sometimes interact with the Player using town specific dialogue.\n",
    "In this case in the town of <LOCATION>{example['Location']}</LOCATION>, a <SPEAKER>Guard</SPEAKER>, when the Player character interacts with them, uses the following line of dialogue:\n",
    "<END>\n",
    "\n",
    "Please remember to generate the line of dialogue used by the Guard.\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "    if example['Condition'] is not None:\n",
    "\n",
    "          return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of <EVENT>{example['Event']}</EVENT> and on the condition that <CONDITION>{example['Condition']}</CONDITION>, <SPEAKER>{npc_type}</SPEAKER>, says the following line to the Player character:\n",
    "<END>\n",
    "\n",
    "Please remember to generate the line of dialogue used by the NPC, based on the given context and not a description of what took place.\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\"\n",
    "\n",
    "    return description + f\"\"\"<START>\n",
    "In the world of Skyrim from the game Elder Scrolls V, in the event of <EVENT>{example['Event']}</EVENT>, <SPEAKER>{npc_type}</SPEAKER>, says the following line to the Player character:\n",
    "<END>\n",
    "\n",
    "Please remember to generate the line of dialogue used by the NPC.\n",
    "\n",
    "The generated dialogue should be one line of text with no special tags or formatting, only the text of the dialogue.\n",
    "\n",
    "Generated dialogue:\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T09:51:18.913387500Z",
     "start_time": "2024-06-16T09:51:18.862564900Z"
    }
   },
   "id": "188a7280b29173a8",
   "execution_count": 752
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T09:51:19.054227100Z",
     "start_time": "2024-06-16T09:51:19.035221700Z"
    }
   },
   "id": "508eacd6587ac4c2",
   "execution_count": 752
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " # Create an evaluation data frame for each example in the test dataset\n",
    "eval_df = pd.DataFrame(test_dataset['train'])\n",
    "eval_df['description'] = eval_df.apply(evaluation_func, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T09:51:19.285054100Z",
     "start_time": "2024-06-16T09:51:19.233591Z"
    }
   },
   "id": "71d4c54c7ee90baa",
   "execution_count": 753
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# create a new dataframe from the Dialogue column of the eval_df\n",
    "test_dialogues = eval_df['Dialogue']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T09:51:19.610359Z",
     "start_time": "2024-06-16T09:51:19.588847900Z"
    }
   },
   "id": "39246a2ed90bec3b",
   "execution_count": 754
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "eval_df = eval_df[['description']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T09:51:20.053232900Z",
     "start_time": "2024-06-16T09:51:20.033723100Z"
    }
   },
   "id": "82aa554cb2729b07",
   "execution_count": 755
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                           description\n0    The following text describes a greeting exchan...\n1    The following text describes a greeting exchan...\n2    The following text describes a greeting exchan...\n3    The following text describes a greeting exchan...\n4    The following text describes a greeting exchan...\n..                                                 ...\n176  The following text describes a special interac...\n177  The following text describes a special interac...\n178  The following text describes a special interac...\n179  The following text describes a special interac...\n180  The following text describes a special interac...\n\n[181 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The following text describes a greeting exchan...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The following text describes a greeting exchan...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The following text describes a greeting exchan...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The following text describes a greeting exchan...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The following text describes a greeting exchan...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>The following text describes a special interac...</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>The following text describes a special interac...</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>The following text describes a special interac...</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>The following text describes a special interac...</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>The following text describes a special interac...</td>\n    </tr>\n  </tbody>\n</table>\n<p>181 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T09:51:20.562611500Z",
     "start_time": "2024-06-16T09:51:20.528903200Z"
    }
   },
   "id": "b4bb35650519ba9b",
   "execution_count": 756
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# make the model generate answers for all the dialogues in the eval_df\n",
    "answers = []\n",
    "for i in range(0, len(eval_df)):\n",
    "    model_input = eval_tokenizer(eval_df['description'][i], return_tensors=\"pt\").to(\"cuda\")\n",
    "    ft_model.eval()\n",
    "    with torch.no_grad():\n",
    "        answer = eval_tokenizer.decode(\n",
    "            ft_model.generate(**model_input, max_new_tokens=1250, repetition_penalty=1.25, pad_token_id=2, temperature=0.3, top_p=0.6)[0],\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        answers.append(answer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T10:08:56.609232300Z",
     "start_time": "2024-06-16T10:02:48.707676200Z"
    }
   },
   "id": "4b33017a0f8fce03",
   "execution_count": 761
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "181"
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T10:18:12.315305500Z",
     "start_time": "2024-06-16T10:18:12.262298400Z"
    }
   },
   "id": "f22c08286ca5f1da",
   "execution_count": 762
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#make the answers into a dataframe\n",
    "answers_df = pd.DataFrame(answers, columns=['Dialogue'])\n",
    "#export the answers to an excel file\n",
    "answers_df.to_excel('Llama2_Dialogues_Full.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T10:18:22.231001400Z",
     "start_time": "2024-06-16T10:18:22.198713700Z"
    }
   },
   "id": "1ba6ab9f088d369",
   "execution_count": 763
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Dialogue\n0    The following text describes a greeting exchan...\n1    The following text describes a greeting exchan...\n2    The following text describes a greeting exchan...\n3    The following text describes a greeting exchan...\n4    The following text describes a greeting exchan...\n..                                                 ...\n176  The following text describes a special interac...\n177  The following text describes a special interac...\n178  The following text describes a special interac...\n179  The following text describes a special interac...\n180  The following text describes a special interac...\n\n[181 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dialogue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The following text describes a greeting exchan...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The following text describes a greeting exchan...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The following text describes a greeting exchan...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The following text describes a greeting exchan...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The following text describes a greeting exchan...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>The following text describes a special interac...</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>The following text describes a special interac...</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>The following text describes a special interac...</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>The following text describes a special interac...</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>The following text describes a special interac...</td>\n    </tr>\n  </tbody>\n</table>\n<p>181 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the answers from the excel file answes_test.xlsx with a column named Dialogue\n",
    "answers_df = pd.read_excel('Llama2_Dialogues_Full.xlsx')\n",
    "#name the column Dialogue\n",
    "answers_df.columns = ['Dialogue']\n",
    "answers_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T10:02:03.698111500Z",
     "start_time": "2024-06-16T10:02:03.643345200Z"
    }
   },
   "id": "9012e6e068435f81",
   "execution_count": 760
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#for each line in the answers_df, keep only the text after the Answer: tag\n",
    "answers_df['Dialogue'] = answers_df['Dialogue'].str.split('Generated dialogue:').str[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T10:20:11.178461600Z",
     "start_time": "2024-06-16T10:20:11.162012Z"
    }
   },
   "id": "52ac7453493b3b80",
   "execution_count": 764
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Dialogue\n0       \\nI'm glad I met you! You make me feel safe...\n1                           \\nI'm here if you need me.\n2       \\nI'm glad I met you! You make me feel safe...\n3    \\nI'm glad you came around! I was beginning to...\n4                           \\nI'm here if you need me.\n..                                                 ...\n176  \\n<LINE>You can find some good weapons at the ...\n177  \\n<LINE>If you need supplies for your journey ...\n178  \\n<LINE>You can find some good weapons at the ...\n179     \\n<LINE>You can buy your own home here.</LINE>\n180  \\n<LINE>You bought Vlindrel Hall? That place l...\n\n[181 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dialogue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\\nI'm glad I met you! You make me feel safe...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\\nI'm here if you need me.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\\nI'm glad I met you! You make me feel safe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\\nI'm glad you came around! I was beginning to...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\\nI'm here if you need me.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>\\n&lt;LINE&gt;You can find some good weapons at the ...</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>\\n&lt;LINE&gt;If you need supplies for your journey ...</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>\\n&lt;LINE&gt;You can find some good weapons at the ...</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>\\n&lt;LINE&gt;You can buy your own home here.&lt;/LINE&gt;</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>\\n&lt;LINE&gt;You bought Vlindrel Hall? That place l...</td>\n    </tr>\n  </tbody>\n</table>\n<p>181 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T10:20:12.622545Z",
     "start_time": "2024-06-16T10:20:12.601064800Z"
    }
   },
   "id": "e5f248355df5dc9f",
   "execution_count": 765
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#export the answers to an excel file\n",
    "answers_df.to_excel('Llama2_Dialogues_Answers_Only.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T10:43:06.293872600Z",
     "start_time": "2024-06-16T10:43:06.250912600Z"
    }
   },
   "id": "6d7f39c2ca00a11e",
   "execution_count": 795
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import the answers from the excel file answes_test.xlsx with a column named Dialogue\n",
    "answers_df = pd.read_excel('Llama2_Dialogues_Answers_Only.xlsx')\n",
    "#name the column Dialogue\n",
    "answers_df.columns = ['Dialogue']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T10:52:12.027649400Z",
     "start_time": "2024-06-16T10:52:11.998634700Z"
    }
   },
   "id": "4aa21490c416d8fb",
   "execution_count": 802
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Dialogue\n0       \\nI'm glad I met you! You make me feel safe...\n1                           \\nI'm here if you need me.\n2       \\nI'm glad I met you! You make me feel safe...\n3    \\nI'm glad you came around! I was beginning to...\n4                           \\nI'm here if you need me.\n..                                                 ...\n176  \\n<LINE>You can find some good weapons at the ...\n177  \\n<LINE>If you need supplies for your journey ...\n178  \\n<LINE>You can find some good weapons at the ...\n179     \\n<LINE>You can buy your own home here.</LINE>\n180  \\n<LINE>You bought Vlindrel Hall? That place l...\n\n[181 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dialogue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\\nI'm glad I met you! You make me feel safe...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\\nI'm here if you need me.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\\nI'm glad I met you! You make me feel safe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\\nI'm glad you came around! I was beginning to...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\\nI'm here if you need me.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>\\n&lt;LINE&gt;You can find some good weapons at the ...</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>\\n&lt;LINE&gt;If you need supplies for your journey ...</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>\\n&lt;LINE&gt;You can find some good weapons at the ...</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>\\n&lt;LINE&gt;You can buy your own home here.&lt;/LINE&gt;</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>\\n&lt;LINE&gt;You bought Vlindrel Hall? That place l...</td>\n    </tr>\n  </tbody>\n</table>\n<p>181 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T10:52:12.769554200Z",
     "start_time": "2024-06-16T10:52:12.736732800Z"
    }
   },
   "id": "889a1d8e9a814031",
   "execution_count": 803
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Dialogue\n0         I'm glad I met you! You make me feel safe...\n1                             I'm here if you need me.\n2         I'm glad I met you! You make me feel safe...\n3    I'm glad you came around! I was beginning to t...\n4                             I'm here if you need me.\n..                                                 ...\n176  You can find some good weapons at the Blacksmith.\n177  If you need supplies for your journey northwar...\n178  You can find some good weapons at the Steed St...\n179                    You can buy your own home here.\n180  You bought Vlindrel Hall? That place looks lik...\n\n[181 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dialogue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I'm glad I met you! You make me feel safe...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I'm here if you need me.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I'm glad I met you! You make me feel safe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I'm glad you came around! I was beginning to t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I'm here if you need me.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>You can find some good weapons at the Blacksmith.</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>If you need supplies for your journey northwar...</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>You can find some good weapons at the Steed St...</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>You can buy your own home here.</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>You bought Vlindrel Hall? That place looks lik...</td>\n    </tr>\n  </tbody>\n</table>\n<p>181 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#itterate through the answers_df and if the <LINE> </LINE> tags are present, keep the text between the tags for all the pairs if there are two pairs keep the second pair\n",
    "import re\n",
    "\n",
    "for i in range(0, len(answers_df)):\n",
    "        \n",
    "    matches = re.findall(r'<LINE>(.*?)</LINE>', answers_df['Dialogue'][i])\n",
    "    if len(matches) > 0:\n",
    "        answers_df['Dialogue'][i] = matches[0]\n",
    "        continue\n",
    "     \n",
    "    matches = re.findall(r'(.*?)</LINE>', answers_df['Dialogue'][i])\n",
    "    if len(matches) > 0:\n",
    "        answers_df['Dialogue'][i] = matches[0]   \n",
    "        continue\n",
    "        \n",
    "    matches = re.findall(r'<DIALOGUE>(.*?)</DIALOGUE>', answers_df['Dialogue'][i])\n",
    "    if len(matches) > 0:\n",
    "        answers_df['Dialogue'][i] = matches[0]\n",
    "        continue\n",
    "        \n",
    "    matches = re.findall(r'<RESPONSE>(.*?)</RESPONSE>', answers_df['Dialogue'][i])\n",
    "    if len(matches) > 0:\n",
    "        answers_df['Dialogue'][i] = matches[0]\n",
    "        continue\n",
    "        \n",
    "    matches = re.findall(r'<END>(.*?)<END>', answers_df['Dialogue'][i])\n",
    "    if len(matches) > 0:\n",
    "        answers_df['Dialogue'][i] = matches[0]\n",
    "        continue\n",
    "        \n",
    "    matches = re.findall(r'<END>(.*?)</END>', answers_df['Dialogue'][i])\n",
    "    if len(matches) > 0:\n",
    "        answers_df['Dialogue'][i] = matches[0]\n",
    "        continue\n",
    "        \n",
    "    matches = re.findall(r'(.*?)</END>', answers_df['Dialogue'][i])\n",
    "    if len(matches) > 0:\n",
    "        answers_df['Dialogue'][i] = matches[0]\n",
    "\n",
    "        \n",
    "    matches = re.findall(r'(.*?)<BR', answers_df['Dialogue'][i])\n",
    "    if len(matches) > 0:\n",
    "        answers_df['Dialogue'][i] = matches[0]\n",
    "    \n",
    "    \n",
    "\n",
    "#remove the /n from the answers_df\n",
    "answers_df = answers_df.replace('\\n', '', regex=True)\n",
    "\n",
    "#add at the 154 place this I've never been there myself... but I hear it's quite nice this time of year.\n",
    "answers_df['Dialogue'][154] = \"I've never been there myself... but I hear it's quite nice this time of year.\"\n",
    "\n",
    "answers_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T11:01:55.642907600Z",
     "start_time": "2024-06-16T11:01:55.597957900Z"
    }
   },
   "id": "d67dc7444ea4b6ea",
   "execution_count": 809
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# remove the from the test dialogues\n",
    "test_dialogues = test_dialogues.str.replace('\"', '')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T11:02:14.132136100Z",
     "start_time": "2024-06-16T11:02:14.086620100Z"
    }
   },
   "id": "8e5b71cc4380e9ea",
   "execution_count": 810
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0                         It's so good to see you again.\n1                                        Need something?\n2      Divines bless you. May the ground you walk qua...\n3         May your next fight bring you victory, friend.\n4                                      What do you need?\n                             ...                        \n176    There's a small skeever den just east of the c...\n177    If you're heading east, stay clear of Hillgrun...\n178    Beware of Frostmere Crypt, friend. Heard some ...\n179    Thinking of settling in? There's a home for sa...\n180    Ah, Vlindrel Hall's a fine home, if you can af...\nName: Dialogue, Length: 181, dtype: object"
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dialogues"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T11:02:14.869335400Z",
     "start_time": "2024-06-16T11:02:14.803461600Z"
    }
   },
   "id": "8002a7787c8f2442",
   "execution_count": 811
  },
  {
   "cell_type": "markdown",
   "id": "bef0d5c5cee19e4f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# BERT Score"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.859535\n",
      "Average Recall: 0.86564714\n",
      "Average F1 Score: 0.86227536\n"
     ]
    }
   ],
   "source": [
    "# Calculate BERTScore\n",
    "from bert_score import score\n",
    "import numpy as np\n",
    "\n",
    "# Lists of candidates and references\n",
    "candidates = answers_df['Dialogue'].tolist()\n",
    "references = test_dialogues.tolist()\n",
    "# Ensure that each candidate has a corresponding reference\n",
    "assert len(candidates) == len(references), \"Each candidate must have a corresponding reference.\"\n",
    "\n",
    "# Calculate BERTScore for each pair\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for cand, ref in zip(candidates, references):\n",
    "    P, R, F1 = score([cand], [ref], lang='en')\n",
    "    precision_scores.append(P.numpy())\n",
    "    recall_scores.append(R.numpy())\n",
    "    f1_scores.append(F1.numpy())\n",
    "    \n",
    "\n",
    "# Calculate the average of each metric\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_recall = np.mean(recall_scores)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "\n",
    "print(\"Average Precision:\", average_precision)\n",
    "print(\"Average Recall:\", average_recall)\n",
    "print(\"Average F1 Score:\", average_f1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T11:05:28.469959900Z",
     "start_time": "2024-06-16T11:02:18.323497200Z"
    }
   },
   "id": "529e21fd0e7f1d0f",
   "execution_count": 812
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1 Scores: {'f': 0.12314344545224126, 'p': 0.12997183785691047, 'r': 0.1384536186371461}\n",
      "Average ROUGE-2 Scores: {'f': 0.04162690138819, 'p': 0.04457745037855535, 'r': 0.04254971014519417}\n",
      "Average ROUGE-L Scores: {'f': 0.11882809208193006, 'p': 0.12534358550766364, 'r': 0.1330526659986244}\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from rouge import Rouge\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress warnings if necessary\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Assuming the DataFrame and columns are properly set\n",
    "# Ensure these columns contain strings\n",
    "candidates = answers_df['Dialogue'].tolist()  \n",
    "references = test_dialogues.tolist()  \n",
    "\n",
    "# Ensure that each candidate has a corresponding reference\n",
    "assert len(candidates) == len(references), \"Each candidate must have a corresponding reference.\"\n",
    "\n",
    "# Initialize the Rouge object\n",
    "rouge = Rouge()\n",
    "\n",
    "# Initialize dictionaries to hold aggregated scores\n",
    "rouge_1_scores = {'f': [], 'p': [], 'r': []}\n",
    "rouge_2_scores = {'f': [], 'p': [], 'r': []}\n",
    "rouge_l_scores = {'f': [], 'p': [], 'r': []}\n",
    "\n",
    "# Calculate ROUGE scores for each pair\n",
    "for cand, ref in zip(candidates, references):\n",
    "    scores = rouge.get_scores(cand, ref, avg=False)[0]  # Obtain scores for the first (and only) pair\n",
    "    # Store ROUGE scores in respective dictionaries\n",
    "    rouge_1_scores['f'].append(scores['rouge-1']['f'])\n",
    "    rouge_1_scores['p'].append(scores['rouge-1']['p'])\n",
    "    rouge_1_scores['r'].append(scores['rouge-1']['r'])\n",
    "    \n",
    "    rouge_2_scores['f'].append(scores['rouge-2']['f'])\n",
    "    rouge_2_scores['p'].append(scores['rouge-2']['p'])\n",
    "    rouge_2_scores['r'].append(scores['rouge-2']['r'])\n",
    "    \n",
    "    rouge_l_scores['f'].append(scores['rouge-l']['f'])\n",
    "    rouge_l_scores['p'].append(scores['rouge-l']['p'])\n",
    "    rouge_l_scores['r'].append(scores['rouge-l']['r'])\n",
    "\n",
    "# Calculate the average of each ROUGE metric\n",
    "def average_score(score_list):\n",
    "    return sum(score_list) / len(score_list) if score_list else 0\n",
    "\n",
    "print(\"Average ROUGE-1 Scores:\", {k: average_score(v) for k, v in rouge_1_scores.items()})\n",
    "print(\"Average ROUGE-2 Scores:\", {k: average_score(v) for k, v in rouge_2_scores.items()})\n",
    "print(\"Average ROUGE-L Scores:\", {k: average_score(v) for k, v in rouge_l_scores.items()})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T11:05:57.224932500Z",
     "start_time": "2024-06-16T11:05:57.165694100Z"
    }
   },
   "id": "7e534de18988c19a",
   "execution_count": 813
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
